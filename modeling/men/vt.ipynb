{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ae1beed",
   "metadata": {},
   "source": [
    "# USA not likely to medal\n",
    "\n",
    "## Scalinbg doesn't improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4d2aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from mlxtend.preprocessing import minmax_scaling\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a396ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Combine_Data/men/vt_encoded.csv')\n",
    "olymp = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_vt.csv')\n",
    "vtnames = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_vtnames.csv')\n",
    "vtolymp = pd.read_csv('../../Data/cleandata22-23/men22_23.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4ac61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp=olymp.drop(columns=['round_AAfinal', 'round_AAqual', 'round_TeamFinal', 'round_final',\n",
    "       'round_qual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "355949a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rank'] = df['Rank'].replace('â€”', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7afc221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rank'] = pd.to_numeric(df['Rank'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fcebd95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126 entries, 0 to 125\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Rank     126 non-null    int64  \n",
      " 1   D        126 non-null    float64\n",
      " 2   E        126 non-null    float64\n",
      " 3   ND       126 non-null    float64\n",
      " 4   Total    126 non-null    float64\n",
      " 5   D.1      126 non-null    float64\n",
      " 6   E.1      126 non-null    float64\n",
      " 7   ND.1     126 non-null    float64\n",
      " 8   Total.1  126 non-null    float64\n",
      " 9   year     126 non-null    int64  \n",
      " 10  Average  126 non-null    float64\n",
      " 11  medal    126 non-null    int64  \n",
      " 12  Name     126 non-null    int64  \n",
      " 13  Nation   126 non-null    int64  \n",
      "dtypes: float64(9), int64(5)\n",
      "memory usage: 13.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "385b37cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>D Score</th>\n",
       "      <th>E Score</th>\n",
       "      <th>Pen.</th>\n",
       "      <th>Total</th>\n",
       "      <th>year</th>\n",
       "      <th>Name</th>\n",
       "      <th>nation</th>\n",
       "      <th>round_TeamQual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.966</td>\n",
       "      <td>2023</td>\n",
       "      <td>241</td>\n",
       "      <td>67</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank  D Score  E Score  Pen.   Total  year  Name  nation  round_TeamQual\n",
       "0  69.0      4.0    8.966   0.0  12.966  2023   241      67           False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olymp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a13805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>ND</th>\n",
       "      <th>Total</th>\n",
       "      <th>D.1</th>\n",
       "      <th>E.1</th>\n",
       "      <th>ND.1</th>\n",
       "      <th>Total.1</th>\n",
       "      <th>year</th>\n",
       "      <th>Average</th>\n",
       "      <th>medal</th>\n",
       "      <th>Name</th>\n",
       "      <th>Nation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.966</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.933</td>\n",
       "      <td>2019</td>\n",
       "      <td>14.9495</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank    D      E   ND   Total  D.1    E.1  ND.1  Total.1  year  Average  \\\n",
       "0     1  5.6  9.366  0.0  14.966  5.6  9.333   0.0   14.933  2019  14.9495   \n",
       "\n",
       "   medal  Name  Nation  \n",
       "0      0    34      33  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc4b7db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp=olymp.drop(columns=['round_TeamQual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd233062",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['Total', 'D.1', 'E.1','ND.1','Total.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "488b49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'D':'D Score', 'E':'E Score',\n",
    "                    'ND': 'Pen.', 'Average': 'Total', 'Nation':'nation'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9338130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympz=olymp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eb33cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2816c28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15, 16, 18, 19,\n",
       "       20,  9, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfz['Rank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e12495c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Random Forest\n",
      "Accuracy: 0.9524\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        40\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95        42\n",
      "   macro avg       0.48      0.50      0.49        42\n",
      "weighted avg       0.91      0.95      0.93        42\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40  0]\n",
      " [ 2  0]]\n",
      "\n",
      "Classifier: AdaBoost\n",
      "Accuracy: 0.9048\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95        40\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.90        42\n",
      "   macro avg       0.61      0.71      0.64        42\n",
      "weighted avg       0.94      0.90      0.92        42\n",
      "\n",
      "Confusion Matrix:\n",
      "[[37  3]\n",
      " [ 1  1]]\n",
      "\n",
      "Classifier: SVM\n",
      "Accuracy: 0.9524\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        40\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95        42\n",
      "   macro avg       0.48      0.50      0.49        42\n",
      "weighted avg       0.91      0.95      0.93        42\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40  0]\n",
      " [ 2  0]]\n",
      "\n",
      "Classifier: K-Nearest Neighbors\n",
      "Accuracy: 0.9524\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        40\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95        42\n",
      "   macro avg       0.48      0.50      0.49        42\n",
      "weighted avg       0.91      0.95      0.93        42\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40  0]\n",
      " [ 2  0]]\n",
      "\n",
      "Classifier: Decision Tree\n",
      "Accuracy: 0.8810\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.94        40\n",
      "           1       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.88        42\n",
      "   macro avg       0.59      0.70      0.61        42\n",
      "weighted avg       0.94      0.88      0.90        42\n",
      "\n",
      "Confusion Matrix:\n",
      "[[36  4]\n",
      " [ 1  1]]\n",
      "\n",
      "Classifier: Naive Bayes\n",
      "Accuracy: 0.6429\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77        40\n",
      "           1       0.12      1.00      0.21         2\n",
      "\n",
      "    accuracy                           0.64        42\n",
      "   macro avg       0.56      0.81      0.49        42\n",
      "weighted avg       0.96      0.64      0.74        42\n",
      "\n",
      "Confusion Matrix:\n",
      "[[25 15]\n",
      " [ 0  2]]\n",
      "\n",
      "Classifier: Neural Network\n",
      "Accuracy: 0.9524\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        40\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95        42\n",
      "   macro avg       0.48      0.50      0.49        42\n",
      "weighted avg       0.91      0.95      0.93        42\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40  0]\n",
      " [ 2  0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Neural Network\": MLPClassifier(),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Iterate through each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    # Create a pipeline with StandardScaler for classifiers that require it\n",
    "    if name in [\"SVM\", \"K-Nearest Neighbors\", \"Neural Network\"]:\n",
    "        clf = make_pipeline(StandardScaler(), clf)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for name, result in results.items():\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"Classification Report:\\n{result['classification_report']}\")\n",
    "    print(f\"Confusion Matrix:\\n{result['confusion_matrix']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0581b526",
   "metadata": {},
   "source": [
    "Classifier: AdaBoost\n",
    "Accuracy: 0.9643\n",
    "\n",
    "Classifier: Decision Tree\n",
    "Accuracy: 0.9643"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "826a918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfz.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8f8aad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126 entries, 0 to 125\n",
      "Data columns (total 9 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Rank     126 non-null    int64  \n",
      " 1   D Score  126 non-null    float64\n",
      " 2   E Score  126 non-null    float64\n",
      " 3   Pen.     126 non-null    float64\n",
      " 4   year     126 non-null    int64  \n",
      " 5   Total    126 non-null    float64\n",
      " 6   medal    126 non-null    int64  \n",
      " 7   Name     126 non-null    int64  \n",
      " 8   nation   126 non-null    int64  \n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 9.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a49a6104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier\n",
      "Accuracy: 0.9286\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        40\n",
      "           1       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.93        42\n",
      "   macro avg       0.70      0.96      0.77        42\n",
      "weighted avg       0.97      0.93      0.94        42\n",
      "\n",
      "Confusion Matrix:\n",
      "[[37  3]\n",
      " [ 0  2]]\n"
     ]
    }
   ],
   "source": [
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Initialize the AdaBoost classifier\n",
    "# CHANGING LEARNIN RATE TO 0.31 RESULTS IN 1.000 \n",
    "clf = AdaBoostClassifier(n_estimators=20, learning_rate=.37321)\n",
    "\n",
    "# Fit the model to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"AdaBoost Classifier\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7874f4ae",
   "metadata": {},
   "source": [
    "above df has no false negatives, meaning, its not incorrectly selecting someone who medaled to not medal. and 3 False Positives, where saying 3 people medaled who actually didnt'. I'd rather pick some people who wont medal than leave out people who will medal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ece0d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp=olympz.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2990110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_column_order = ['Rank', 'D Score', 'E Score', 'Pen.', 'year', 'Total',\n",
    "                        'Name', 'nation'] # Add all your column names in the desired order\n",
    "\n",
    "# Create a new DataFrame with the desired column order\n",
    "olymp = olymp[desired_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6eead1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(olymp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "854c9aee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ypreds  = pd.Series(y_pred)\n",
    "olymp['ypred']=ypreds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "818ec271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ypred\n",
       "0    2987\n",
       "1     112\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olymp['ypred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "938cf148",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = olymp[olymp['ypred'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1d50ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([613,  61, 272, 370, 369, 244,  16, 614, 271,  73, 151, 141, 152])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86c4f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_encoded_values = [613,  61, 272, 370, 369, 244,  16, 614, 271,  73, 151, 141, 152]\n",
    "\n",
    "# Filter the DataFrame to get the corresponding \"Name\" values\n",
    "result = vtnames.loc[vtnames['Name_encoded'].isin(name_encoded_values), 'Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ef5fcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['santiago agostinelli', 'artur davtyan',\n",
       "       'houssem eddine hamadouche', 'julian jato', 'julian ezequiel jato',\n",
       "       'gagik khachikyan', 'ahmed anis maoudj', 'santiago mayol',\n",
       "       'hillal metidji', 'benedek tomcsanyi', 'daniel villafane',\n",
       "       'daniel angel villafane', 'daniel villafaÃ±e'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "911cf451",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtolymp[\"Name\"]=vtolymp[\"Name\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56e2262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_filter = ['santiago agostinelli', 'artur davtyan',\n",
    "       'houssem eddine hamadouche', 'julian jato', 'julian ezequiel jato',\n",
    "       'gagik khachikyan', 'ahmed anis maoudj', 'santiago mayol',\n",
    "       'hillal metidji', 'benedek tomcsanyi', 'daniel villafane',\n",
    "       'daniel angel villafane', 'daniel villafaÃ±e']\n",
    "\n",
    "# Filter the DataFrame to get rows with the specified \"Name\" values\n",
    "result = vtolymp[vtolymp['Name'].isin(names_to_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62f7d8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "ARM    165\n",
       "ARG     94\n",
       "HUN     46\n",
       "ALG     21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1baf5a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Competition</th>\n",
       "      <th>Round</th>\n",
       "      <th>Location</th>\n",
       "      <th>Apparatus</th>\n",
       "      <th>Rank</th>\n",
       "      <th>D_Score</th>\n",
       "      <th>E_Score</th>\n",
       "      <th>Penalty</th>\n",
       "      <th>Score</th>\n",
       "      <th>Total_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Country, Date, Gender, Competition, Round, Location, Apparatus, Rank, D_Score, E_Score, Penalty, Score, Total_Score]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result['Country']=='USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77005856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
