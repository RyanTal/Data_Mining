{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa227c7",
   "metadata": {},
   "source": [
    "# Men's team unlikely to medal in floor\n",
    "\n",
    "## scaling not needed\n",
    "## Used optimized params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34825429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from mlxtend.preprocessing import minmax_scaling\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, fbeta_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971b2c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d9ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Combine_Data/men/fx_encoded.csv')\n",
    "olymp = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_fx.csv')\n",
    "fxnames = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_fxnames.csv')\n",
    "fxolymp = pd.read_csv('../../Data/cleandata22-23/men22_23.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26f1ff51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 538 entries, 0 to 537\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Rank         538 non-null    int64  \n",
      " 1   D            538 non-null    float64\n",
      " 2   E            538 non-null    float64\n",
      " 3   ND           538 non-null    float64\n",
      " 4   year         538 non-null    int64  \n",
      " 5   Total        538 non-null    float64\n",
      " 6   medal        538 non-null    int64  \n",
      " 7   Name         538 non-null    int64  \n",
      " 8   Nation       538 non-null    int64  \n",
      " 9   round_final  538 non-null    bool   \n",
      " 10  round_qual   538 non-null    bool   \n",
      "dtypes: bool(2), float64(4), int64(5)\n",
      "memory usage: 39.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd382322",
   "metadata": {},
   "source": [
    "# Base line using ZeroR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aace2254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeroR Classifier\n",
      "Accuracy: 0.9722\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       105\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.97       108\n",
      "   macro avg       0.49      0.50      0.49       108\n",
      "weighted avg       0.95      0.97      0.96       108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[105   0]\n",
      " [  3   0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns=['medal'])  \n",
    "y = df['medal']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize  ZeroR classifier\n",
    "zero_r_clf = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "\n",
    "zero_r_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on  test data\n",
    "y_pred = zero_r_clf.predict(X_test)\n",
    "\n",
    "# Evaluate  model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"ZeroR Classifier\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6fc36",
   "metadata": {},
   "source": [
    "# Model Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92b19f47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Random Forest\n",
      "Accuracy: 0.9815\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       105\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.98       108\n",
      "   macro avg       0.99      0.67      0.75       108\n",
      "weighted avg       0.98      0.98      0.98       108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[105   0]\n",
      " [  2   1]]\n",
      "\n",
      "Classifier: AdaBoost\n",
      "Accuracy: 0.9815\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       105\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.98       108\n",
      "   macro avg       0.99      0.67      0.75       108\n",
      "weighted avg       0.98      0.98      0.98       108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[105   0]\n",
      " [  2   1]]\n",
      "\n",
      "Classifier: SVM\n",
      "Accuracy: 0.9722\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       105\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.97       108\n",
      "   macro avg       0.49      0.50      0.49       108\n",
      "weighted avg       0.95      0.97      0.96       108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[105   0]\n",
      " [  3   0]]\n",
      "\n",
      "Classifier: K-Nearest Neighbors\n",
      "Accuracy: 0.9722\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       105\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.97       108\n",
      "   macro avg       0.49      0.50      0.49       108\n",
      "weighted avg       0.95      0.97      0.96       108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[105   0]\n",
      " [  3   0]]\n",
      "\n",
      "Classifier: Decision Tree\n",
      "Accuracy: 0.9722\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       105\n",
      "           1       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.97       108\n",
      "   macro avg       0.74      0.66      0.69       108\n",
      "weighted avg       0.97      0.97      0.97       108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[104   1]\n",
      " [  2   1]]\n",
      "\n",
      "Classifier: Naive Bayes\n",
      "Accuracy: 0.9444\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       105\n",
      "           1       0.33      1.00      0.50         3\n",
      "\n",
      "    accuracy                           0.94       108\n",
      "   macro avg       0.67      0.97      0.74       108\n",
      "weighted avg       0.98      0.94      0.96       108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[99  6]\n",
      " [ 0  3]]\n",
      "\n",
      "Classifier: Neural Network\n",
      "Accuracy: 0.9630\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       105\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.96       108\n",
      "   macro avg       0.49      0.50      0.49       108\n",
      "weighted avg       0.94      0.96      0.95       108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[104   1]\n",
      " [  3   0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Neural Network\": MLPClassifier(),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Iterate through each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    # Create a pipeline with StandardScaler for classifiers that require it\n",
    "    if name in [\"SVM\", \"K-Nearest Neighbors\", \"Neural Network\"]:\n",
    "        clf = make_pipeline(StandardScaler(), clf)\n",
    "\n",
    "    # Fit model to training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "    }\n",
    "\n",
    "for name, result in results.items():\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"Classification Report:\\n{result['classification_report']}\")\n",
    "    print(f\"Confusion Matrix:\\n{result['confusion_matrix']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a29703",
   "metadata": {},
   "source": [
    "Classifier: Random Forest\n",
    "Accuracy: 0.9815\n",
    "\n",
    "Classifier: AdaBoost\n",
    "Accuracy: 0.9815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a9c6156",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp.rename(columns={'D Score': 'D', 'E Score': 'E',\n",
    "                     'Pen.': 'ND', 'nation': 'Nation'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96050009",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp=olymp.drop(columns=['round_TeamFinal', 'round_AAfinal', 'round_TeamQual']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fdb26c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_column_order = ['Rank', 'D', 'E', 'ND', 'year', 'Total', 'Name', 'Nation',\n",
    "       'round_final', 'round_qual']\n",
    "\n",
    "# Create DataFrame with desired column order\n",
    "olymp = olymp[desired_column_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4c618f",
   "metadata": {},
   "source": [
    "# Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c21b642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier with Grid Search Results\n",
      "Best Parameters: {'learning_rate': 0.1, 'n_estimators': 30}\n",
      "Accuracy: 0.9907\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       105\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       108\n",
      "   macro avg       0.88      1.00      0.93       108\n",
      "weighted avg       0.99      0.99      0.99       108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[104   1]\n",
      " [  0   3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize AdaBoost classifier\n",
    "base_classifier = DecisionTreeClassifier(max_depth=3)\n",
    "clf = AdaBoostClassifier(base_classifier)\n",
    "\n",
    "# Specify parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 20, 30],\n",
    "    'learning_rate': [0.01, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit model to training data using Grid Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters from grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Initialize AdaBoost classifier with best parameters\n",
    "best_clf = AdaBoostClassifier(base_classifier, n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'])\n",
    "\n",
    "# Fit model to training data\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Evaluate model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"AdaBoost Classifier with Grid Search Results\")\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93292b02",
   "metadata": {},
   "source": [
    "# Final hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8c2a6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier with Best Hyperparameters\n",
      "Accuracy: 0.9815\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       105\n",
      "           1       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.98       108\n",
      "   macro avg       0.83      0.83      0.83       108\n",
      "weighted avg       0.98      0.98      0.98       108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[104   1]\n",
      " [  1   2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize AdaBoost classifier with best hyperparameters\n",
    "base_classifier = DecisionTreeClassifier(max_depth=3)\n",
    "best_clf = AdaBoostClassifier(base_classifier, n_estimators=30, learning_rate=0.1)\n",
    "\n",
    "# Fit the model to training data\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_prob = best_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Adjust the threshold\n",
    "threshold = 0.5  \n",
    "y_pred_adjusted = (y_pred_prob > threshold).astype(int)\n",
    "\n",
    "# Evaluate model's performance with adjusted threshold\n",
    "accuracy = accuracy_score(y_test, y_pred_adjusted)\n",
    "report = classification_report(y_test, y_pred_adjusted)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_adjusted)\n",
    "\n",
    "print(\"AdaBoost Classifier with Best Hyperparameters\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a9df47",
   "metadata": {},
   "source": [
    "# Model Trained earlier using 2023/2022 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f21e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning olymp df\n",
    "\n",
    "olymp = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_fx.csv')\n",
    "\n",
    "\n",
    "olymp.rename(columns={'D Score': 'D', 'E Score': 'E',\n",
    "                     'Pen.': 'ND', 'nation': 'Nation'}, inplace=True)\n",
    "olymp=olymp.drop(columns=['round_TeamFinal', 'round_AAfinal', 'round_TeamQual']) \n",
    "desired_column_order = ['Rank', 'D', 'E', 'ND', 'year', 'Total', 'Name', 'Nation',\n",
    "       'round_final', 'round_qual'] \n",
    "\n",
    "olymp = olymp[desired_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0323938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_clf.predict(olymp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37b4de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds  = pd.Series(y_pred)\n",
    "olymp['ypred']=ypreds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53db9f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ypred\n",
       "0    2424\n",
       "1      15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olymp['ypred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2410b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = olymp[olymp['ypred'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5585a161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 74, 264, 308, 249, 733, 333, 603,  85])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e23d44",
   "metadata": {},
   "source": [
    "# fxnames used to match encoded names with actual names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed4188f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_encoded_values = [74, 264, 308, 249, 733, 451, 333, 603,  85]\n",
    "\n",
    "result = fxnames.loc[fxnames['Name_encoded'].isin(name_encoded_values), 'Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2c3a82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aurel benovic', 'harry hepworth', 'jake jarman',\n",
       "       'giarnni regini moran', 'weide su', 'luke whitehouse',\n",
       "       'jiaxing yang', 'rayderley zapata', 'boheng zhang'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a4755",
   "metadata": {},
   "source": [
    "# fxolymp used to get country info from name list above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12131912",
   "metadata": {},
   "outputs": [],
   "source": [
    "fxolymp[\"Name\"]=fxolymp[\"Name\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d954da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_filter = ['aurel benovic', 'harry hepworth', 'jake jarman',\n",
    "       'giarnni regini moran', 'weide su', 'luke whitehouse',\n",
    "       'jiaxing yang', 'rayderley zapata', 'boheng zhang']\n",
    "\n",
    "result = fxolymp[fxolymp['Name'].isin(names_to_filter)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "929e217d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "GBR    237\n",
       "CHN     77\n",
       "CRO     41\n",
       "ESP     27\n",
       "ENG     23\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9098c46d",
   "metadata": {},
   "source": [
    "# Find names from USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2af24d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = result[result['Country']=='USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73b6bae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa['Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610cd19a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
