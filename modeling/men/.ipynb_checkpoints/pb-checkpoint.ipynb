{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a0abe07",
   "metadata": {},
   "source": [
    "# yul moldauer and curran phillips in Parallel Bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e8f2443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from mlxtend.preprocessing import minmax_scaling\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b94c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Combine_Data/men/pb_encoded.csv')\n",
    "olymp = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_pb.csv')\n",
    "pbnames = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_pbnames.csv')\n",
    "pbolymp = pd.read_csv('../../Data/cleandata22-23/men22_23.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ff83f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name_counts = df['Name'].value_counts()\n",
    "\n",
    "# Extract names that appear 2 or more times\n",
    "names_with_multiple_occurrences = name_counts[name_counts >= 2].index\n",
    "\n",
    "# Filter the DataFrame based on the condition\n",
    "df_filtered_names = df[df['Name'].isin(names_with_multiple_occurrences)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c28216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_filtered_names.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd6a9a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 316 entries, 0 to 484\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Rank         316 non-null    int64  \n",
      " 1   D            316 non-null    float64\n",
      " 2   E            316 non-null    float64\n",
      " 3   ND           316 non-null    float64\n",
      " 4   Total        316 non-null    float64\n",
      " 5   year         316 non-null    int64  \n",
      " 6   medal        316 non-null    int64  \n",
      " 7   Name         316 non-null    int64  \n",
      " 8   Nation       316 non-null    int64  \n",
      " 9   round_final  316 non-null    bool   \n",
      " 10  round_qual   316 non-null    bool   \n",
      "dtypes: bool(2), float64(4), int64(5)\n",
      "memory usage: 25.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c15cdb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>ND</th>\n",
       "      <th>Total</th>\n",
       "      <th>year</th>\n",
       "      <th>medal</th>\n",
       "      <th>Name</th>\n",
       "      <th>Nation</th>\n",
       "      <th>round_final</th>\n",
       "      <th>round_qual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>8.266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.066</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.2</td>\n",
       "      <td>8.433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.633</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.366</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>69</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.200</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.066</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>39</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank    D      E   ND   Total  year  medal  Name  Nation  round_final  \\\n",
       "0     1  6.8  8.266  0.0  15.066  2019      0   295      13         True   \n",
       "1     2  6.2  8.433  0.0  14.633  2019      0    10      69         True   \n",
       "2     3  6.5  7.866  0.0  14.366  2019      1    90      69         True   \n",
       "3     4  6.0  8.200  0.0  14.200  2019      0   189       4         True   \n",
       "4     5  5.9  8.166  0.0  14.066  2019      0   105      39         True   \n",
       "\n",
       "   round_qual  \n",
       "0       False  \n",
       "1       False  \n",
       "2       False  \n",
       "3       False  \n",
       "4       False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b80ddc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Logistic Regression\n",
      "Accuracy: 0.9810\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       103\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.98       105\n",
      "   macro avg       0.49      0.50      0.50       105\n",
      "weighted avg       0.96      0.98      0.97       105\n",
      "\n",
      "Confusion Matrix:\n",
      "[[103   0]\n",
      " [  2   0]]\n",
      "\n",
      "Classifier: XGBoost\n",
      "Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       103\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       105\n",
      "   macro avg       1.00      1.00      1.00       105\n",
      "weighted avg       1.00      1.00      1.00       105\n",
      "\n",
      "Confusion Matrix:\n",
      "[[103   0]\n",
      " [  0   2]]\n",
      "\n",
      "Classifier: SVM\n",
      "Accuracy: 0.9810\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       103\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.98       105\n",
      "   macro avg       0.49      0.50      0.50       105\n",
      "weighted avg       0.96      0.98      0.97       105\n",
      "\n",
      "Confusion Matrix:\n",
      "[[103   0]\n",
      " [  2   0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Assuming you have a DataFrame df with your data\n",
    "# For example, let's assume 'medal' is the target column, and you want to drop it for the features\n",
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=9)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Iterate through each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    # Create a pipeline with StandardScaler for classifiers that require it\n",
    "    if name != \"XGBoost\":\n",
    "        clf = make_pipeline(StandardScaler(), clf)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for name, result in results.items():\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"Classification Report:\\n{result['classification_report']}\")\n",
    "    print(f\"Confusion Matrix:\\n{result['confusion_matrix']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be45c1b8",
   "metadata": {},
   "source": [
    "Classifier: AdaBoost\n",
    "Accuracy: 0.9902\n",
    "\n",
    "Classifier: Decision Tree\n",
    "Accuracy: 0.9853\n",
    "\n",
    "Classifier: Random Forest\n",
    "Accuracy: 0.9853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d1a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Combine_Data/men/pb_encoded.csv')\n",
    "\n",
    "name_counts = df['Name'].value_counts()\n",
    "\n",
    "# Extract names that appear 2 or more times\n",
    "names_with_multiple_occurrences = name_counts[name_counts >= 2].index\n",
    "\n",
    "# Filter the DataFrame based on the condition\n",
    "df_filtered_names = df[df['Name'].isin(names_with_multiple_occurrences)]\n",
    "df=df_filtered_names.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "475401cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200}\n",
      "Accuracy: 0.9905\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have a DataFrame df with your data\n",
    "# For example, let's assume 'medal' is the target column, and you want to drop it for the features\n",
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "# Define a parameter grid to search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, scoring='accuracy', cv=3)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Use the best parameters to initialize the final model\n",
    "final_model = XGBClassifier(**best_params)\n",
    "\n",
    "# Train the final model\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "143ecad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "Precision: 0.75\n",
      "Recall: 1.00\n",
      "Confusion Matrix:\n",
      "[[101   1]\n",
      " [  0   3]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your original DataFrame with the features and target variable\n",
    "# Make sure to replace 'your_target_column' with the actual name of your target column\n",
    "\n",
    "X = df.drop(columns=['medal'])\n",
    "y = df['medal']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Use MaxAbsScaler to scale the features\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Set XGBoost parameters based on the best parameters\n",
    "params = {\n",
    "    'learning_rate': 0.2,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "    'n_estimators': 200,\n",
    "    'objective': 'binary:logistic',  # Assuming binary classification, change accordingly\n",
    "    'eval_metric': 'logloss',  # Assuming log loss as evaluation metric, change accordingly\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Create and fit the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(**params)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9e10d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_pb.csv')\n",
    "olymp.rename(columns={'D Score': 'D', 'E Score': 'E',\n",
    "                     'Pen.': 'ND', 'nation': 'Nation'}, inplace=True)\n",
    "olymp=olymp.drop(columns=['round_TeamFinal', 'round_AAfinal', 'round_TeamQual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c49ea5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = clf.predict(olymp)\n",
    "# y_pred = gpc.predict(olymp)\n",
    "# y_pred = stacking_clf.predict(olymp)\n",
    "\n",
    "# y_pred=rf_classifier.predict(olymp)\n",
    "# y_pred = xgb_classifier.predict\n",
    "# y_pred = xgb_classifier.predict(olymp)\n",
    "\n",
    "y_pred=final_model.predict(olymp)\n",
    "\n",
    "# y_pred=knn_model.predict(olymp)\n",
    "\n",
    "\n",
    "# Use MaxAbsScaler to scale the features in 'olymp'\n",
    "olymp_scaled = scaler.transform(olymp)\n",
    "# y_pred = knn_model.predict(olymp_scaled)\n",
    "y_pred=final_model.predict(olymp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "793ae23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds  = pd.Series(y_pred)\n",
    "olymp['ypred']=ypreds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b623e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = olymp[olymp['ypred'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdebf1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([390, 286, 747, 746,  20, 139, 719, 552, 384, 716, 333,  21])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1779cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_encoded_values = [390, 286, 747, 746,  20, 139, 719, 552, 384, 716, 333,  21]\n",
    "\n",
    "# Filter the DataFrame to get the corresponding \"Name\" values\n",
    "result = pbnames.loc[pbnames['Name_encoded'].isin(name_encoded_values), 'Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e67c6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kazuma kaya', 'illia kovtun', 'yul moldauer',\n",
       "       'yul kyung tae moldauer', 'ahmet onder', 'curran phillips',\n",
       "       'wichol ri', 'noe seifert', 'kakeru tanigawa', 'wataru tanigawa',\n",
       "       'jingyuan zou', 'ahmet önder'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffc31876",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbolymp[\"Name\"]=pbolymp[\"Name\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef945b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_filter =['kazuma kaya', 'illia kovtun', 'yul moldauer',\n",
    "       'yul kyung tae moldauer', 'ahmet onder', 'curran phillips',\n",
    "       'wichol ri', 'noe seifert', 'kakeru tanigawa', 'wataru tanigawa',\n",
    "       'jingyuan zou', 'ahmet önder']\n",
    "# Filter the DataFrame to get rows with the specified \"Name\" values\n",
    "result = pbolymp[pbolymp['Name'].isin(names_to_filter)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39bd774f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "UKR    151\n",
       "USA     96\n",
       "JPN     84\n",
       "TUR     62\n",
       "SUI     56\n",
       "CHN     16\n",
       "PRK     11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea506b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = result[result['Country']=='USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "716b31d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['yul moldauer', 'yul kyung tae moldauer', 'curran phillips'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa['Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922c2f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
