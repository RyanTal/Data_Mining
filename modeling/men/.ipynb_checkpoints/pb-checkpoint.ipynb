{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a0abe07",
   "metadata": {},
   "source": [
    "# yul moldauer and curran phillips in Parallel Bars\n",
    "\n",
    "## SWcaling - no improvement\n",
    "## GirdSearch used\n",
    "## k-folds-validatio n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e8f2443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from mlxtend.preprocessing import minmax_scaling\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, fbeta_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55327fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b94c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Combine_Data/men/pb_encoded.csv')\n",
    "olymp = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_pb.csv')\n",
    "pbnames = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_pbnames.csv')\n",
    "pbolymp = pd.read_csv('../../Data/cleandata22-23/men22_23.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dffaf40",
   "metadata": {},
   "source": [
    "# Base line using ZeroR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15cdb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeroR Classifier\n",
      "Accuracy: 0.9689\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       156\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.97       161\n",
      "   macro avg       0.48      0.50      0.49       161\n",
      "weighted avg       0.94      0.97      0.95       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[156   0]\n",
      " [  5   0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns=['medal'])  \n",
    "y = df['medal']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=9)\n",
    "\n",
    "# Initialize  ZeroR classifier\n",
    "zero_r_clf = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "\n",
    "zero_r_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on  test data\n",
    "y_pred = zero_r_clf.predict(X_test)\n",
    "\n",
    "# Evaluate  model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"ZeroR Classifier\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e71d22f",
   "metadata": {},
   "source": [
    "# Model Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1614f56a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Logistic Regression\n",
      "Accuracy: 0.9627\n",
      "F2-Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       156\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.96       161\n",
      "   macro avg       0.48      0.50      0.49       161\n",
      "weighted avg       0.94      0.96      0.95       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[155   1]\n",
      " [  5   0]]\n",
      "\n",
      "Classifier: XGBoost\n",
      "Accuracy: 0.9752\n",
      "F2-Score: 0.4348\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       156\n",
      "           1       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.98       161\n",
      "   macro avg       0.82      0.70      0.74       161\n",
      "weighted avg       0.97      0.98      0.97       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[155   1]\n",
      " [  3   2]]\n",
      "\n",
      "Classifier: Random Forest\n",
      "Accuracy: 0.9752\n",
      "F2-Score: 0.2381\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       156\n",
      "           1       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           0.98       161\n",
      "   macro avg       0.99      0.60      0.66       161\n",
      "weighted avg       0.98      0.98      0.97       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[156   0]\n",
      " [  4   1]]\n",
      "\n",
      "Classifier: AdaBoost\n",
      "Accuracy: 0.9876\n",
      "F2-Score: 0.6522\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       156\n",
      "           1       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.99       161\n",
      "   macro avg       0.99      0.80      0.87       161\n",
      "weighted avg       0.99      0.99      0.99       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[156   0]\n",
      " [  2   3]]\n",
      "\n",
      "Classifier: SVM\n",
      "Accuracy: 0.9689\n",
      "F2-Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       156\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.97       161\n",
      "   macro avg       0.48      0.50      0.49       161\n",
      "weighted avg       0.94      0.97      0.95       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[156   0]\n",
      " [  5   0]]\n",
      "\n",
      "Classifier: K-Nearest Neighbors\n",
      "Accuracy: 0.9689\n",
      "F2-Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       156\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.97       161\n",
      "   macro avg       0.48      0.50      0.49       161\n",
      "weighted avg       0.94      0.97      0.95       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[156   0]\n",
      " [  5   0]]\n",
      "\n",
      "Classifier: Decision Tree\n",
      "Accuracy: 0.9938\n",
      "F2-Score: 0.9615\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       156\n",
      "           1       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.99       161\n",
      "   macro avg       0.92      1.00      0.95       161\n",
      "weighted avg       0.99      0.99      0.99       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[155   1]\n",
      " [  0   5]]\n",
      "\n",
      "Classifier: Naive Bayes\n",
      "Accuracy: 0.7702\n",
      "F2-Score: 0.4032\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.87       156\n",
      "           1       0.12      1.00      0.21         5\n",
      "\n",
      "    accuracy                           0.77       161\n",
      "   macro avg       0.56      0.88      0.54       161\n",
      "weighted avg       0.97      0.77      0.85       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[119  37]\n",
      " [  0   5]]\n",
      "\n",
      "Classifier: Neural Network\n",
      "Accuracy: 0.9130\n",
      "F2-Score: 0.4286\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       156\n",
      "           1       0.20      0.60      0.30         5\n",
      "\n",
      "    accuracy                           0.91       161\n",
      "   macro avg       0.59      0.76      0.63       161\n",
      "weighted avg       0.96      0.91      0.93       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[144  12]\n",
      " [  2   3]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, fbeta_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Assuming you have a DataFrame df with your data\n",
    "# For example, let's assume 'medal' is the target column, and you want to drop it for the features\n",
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=9)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Neural Network\": MLPClassifier(),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Iterate through each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    # Create a pipeline with StandardScaler for classifiers that require it\n",
    "    if name not in [\"XGBoost\", \"Naive Bayes\", \"Neural Network\"]:\n",
    "        clf = make_pipeline(StandardScaler(), clf)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    beta = 2\n",
    "    f2_score = fbeta_score(y_test, y_pred, beta=beta)\n",
    "\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "        \"f2_score\": f2_score,\n",
    "    }\n",
    "\n",
    "for name, result in results.items():\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"F2-Score: {result['f2_score']:.4f}\")\n",
    "    print(f\"Classification Report:\\n{result['classification_report']}\")\n",
    "    print(f\"Confusion Matrix:\\n{result['confusion_matrix']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b80ddc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Logistic Regression\n",
      "Accuracy: 0.9627\n",
      "F2-Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       156\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.96       161\n",
      "   macro avg       0.48      0.50      0.49       161\n",
      "weighted avg       0.94      0.96      0.95       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[155   1]\n",
      " [  5   0]]\n",
      "\n",
      "Classifier: XGBoost\n",
      "Accuracy: 0.9752\n",
      "F2-Score: 0.4348\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       156\n",
      "           1       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.98       161\n",
      "   macro avg       0.82      0.70      0.74       161\n",
      "weighted avg       0.97      0.98      0.97       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[155   1]\n",
      " [  3   2]]\n",
      "\n",
      "Classifier: SVM\n",
      "Accuracy: 0.9689\n",
      "F2-Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       156\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.97       161\n",
      "   macro avg       0.48      0.50      0.49       161\n",
      "weighted avg       0.94      0.97      0.95       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[156   0]\n",
      " [  5   0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Assuming you have a DataFrame df with your data\n",
    "# For example, let's assume 'medal' is the target column, and you want to drop it for the features\n",
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=9)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Iterate through each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    # Create a pipeline with StandardScaler for classifiers that require it\n",
    "    if name != \"XGBoost\":\n",
    "        clf = make_pipeline(StandardScaler(), clf)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    beta = 2\n",
    "    f2_score = fbeta_score(y_test, y_pred, beta=beta)\n",
    "\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "        \"f2_score\": f2_score,\n",
    "    }\n",
    "    \n",
    "for name, result in results.items():\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"F2-Score: {result['f2_score']:.4f}\")\n",
    "    print(f\"Classification Report:\\n{result['classification_report']}\")\n",
    "    print(f\"Confusion Matrix:\\n{result['confusion_matrix']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3d1a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Combine_Data/men/pb_encoded.csv')\n",
    "\n",
    "name_counts = df['Name'].value_counts()\n",
    "\n",
    "# Extract names that appear 2 or more times\n",
    "names_with_multiple_occurrences = name_counts[name_counts >= 2].index\n",
    "\n",
    "# Filter the DataFrame based on condition\n",
    "df_filtered_names = df[df['Name'].isin(names_with_multiple_occurrences)]\n",
    "df=df_filtered_names.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619f82bf",
   "metadata": {},
   "source": [
    "# Grid Search witk k-folds validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4828c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200}\n",
      "Accuracy: 1.0000\n",
      "\n",
      "Fold 2\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200}\n",
      "Accuracy: 0.9688\n",
      "\n",
      "Fold 3\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200}\n",
      "Accuracy: 1.0000\n",
      "\n",
      "Fold 4\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200}\n",
      "Accuracy: 1.0000\n",
      "\n",
      "Fold 5\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200}\n",
      "Accuracy: 1.0000\n",
      "\n",
      "Fold 6\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200}\n",
      "Accuracy: 0.9375\n",
      "\n",
      "Fold 7\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200}\n",
      "Accuracy: 0.9677\n",
      "\n",
      "Fold 8\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200}\n",
      "Accuracy: 0.9677\n",
      "\n",
      "Fold 9\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200}\n",
      "Accuracy: 0.9677\n",
      "\n",
      "Fold 10\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200}\n",
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "# Define a parameter grid to search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Initialize StratifiedKFold for k-fold cross-validation\n",
    "k_folds = 10\n",
    "stratified_kfold = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV with StratifiedKFold\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, scoring='accuracy', cv=stratified_kfold)\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Use the best parameters to initialize the final model\n",
    "final_model = XGBClassifier(**best_params)\n",
    "\n",
    "# Iterate over folds for evaluation\n",
    "for fold, (train_index, test_index) in enumerate(stratified_kfold.split(X, y)):\n",
    "    print(f\"\\nFold {fold + 1}\")\n",
    "\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Train the model for this fold\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on test data for this fold\n",
    "    y_pred = final_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance for this fold\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba2559",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "475401cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200}\n",
      "Accuracy: 0.9905\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have a DataFrame df with your data\n",
    "# For example, let's assume 'medal' is the target column, and you want to drop it for the features\n",
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "# Define a parameter grid to search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, scoring='accuracy', cv=3)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Use the best parameters to initialize the final model\n",
    "final_model = XGBClassifier(**best_params)\n",
    "\n",
    "# Train the final model\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac43b82c",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffa30a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "Rank: 0.1506\n",
      "D: 0.2976\n",
      "E: 0.0712\n",
      "ND: 0.0000\n",
      "Total: 0.0310\n",
      "year: 0.0609\n",
      "Name: 0.1167\n",
      "Nation: 0.2198\n",
      "round_final: 0.0522\n",
      "round_qual: 0.0000\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "Confusion Matrix:\n",
      "[[30  0]\n",
      " [ 0  1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have X_train, X_test, y_train, y_test already defined\n",
    "\n",
    "# MaxAbsScaler to scale features\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Set XGBoost best parameters\n",
    "params = {\n",
    "    'learning_rate': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 1,\n",
    "    'n_estimators': 200,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss', \n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Create and fit XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(**params)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Extract feature importances from the trained XGBoost model\n",
    "feature_importances = xgb_model.feature_importances_\n",
    "\n",
    "# Print feature importances\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in zip(X.columns, feature_importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(X.columns, feature_importances, color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('XGBoost Classifier - Feature Importances')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b589dd6c",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e2756ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "Precision: 0.75\n",
      "Recall: 1.00\n",
      "Confusion Matrix:\n",
      "[[101   1]\n",
      " [  0   3]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import pandas as pd\n",
    "\n",
    "X = df.drop(columns=['medal'])\n",
    "y = df['medal']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# MaxAbsScaler to scale  features\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Set XGBoost best parameters\n",
    "params = {\n",
    "    'learning_rate': 0.2,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "    'n_estimators': 200,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss', \n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Create  fit XGBoost \n",
    "xgb_model = xgb.XGBClassifier(**params)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# prediction\n",
    "y_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06132db",
   "metadata": {},
   "source": [
    "# Model Trained earlier, now using 2023/2022 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9e10d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_pb.csv')\n",
    "olymp.rename(columns={'D Score': 'D', 'E Score': 'E',\n",
    "                     'Pen.': 'ND', 'nation': 'Nation'}, inplace=True)\n",
    "olymp=olymp.drop(columns=['round_TeamFinal', 'round_AAfinal', 'round_TeamQual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c49ea5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=final_model.predict(olymp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "793ae23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds  = pd.Series(y_pred)\n",
    "olymp['ypred']=ypreds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b623e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = olymp[olymp['ypred'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdebf1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([450, 338, 698, 754, 661, 390, 674, 286, 481, 747, 746, 659, 139,\n",
       "       719, 552, 383,  83, 384, 716, 108, 333,  21])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaeb565",
   "metadata": {},
   "source": [
    "# pbnames used to match encoded names with actual names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1779cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_encoded_values = [390, 286, 747, 746,  20, 139, 719, 552, 384, 716, 333,  21]\n",
    "\n",
    "# Filter the DataFrame to get the corresponding \"Name\" values\n",
    "result = pbnames.loc[pbnames['Name_encoded'].isin(name_encoded_values), 'Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e67c6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kazuma kaya', 'illia kovtun', 'yul moldauer',\n",
       "       'yul kyung tae moldauer', 'ahmet onder', 'curran phillips',\n",
       "       'wichol ri', 'noe seifert', 'kakeru tanigawa', 'wataru tanigawa',\n",
       "       'jingyuan zou', 'ahmet önder'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dc845f",
   "metadata": {},
   "source": [
    "# pbolymp used to get country info from name list above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffc31876",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbolymp[\"Name\"]=pbolymp[\"Name\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef945b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_filter =['kazuma kaya', 'illia kovtun', 'yul moldauer',\n",
    "       'yul kyung tae moldauer', 'ahmet onder', 'curran phillips',\n",
    "       'wichol ri', 'noe seifert', 'kakeru tanigawa', 'wataru tanigawa',\n",
    "       'jingyuan zou', 'ahmet önder']\n",
    "# Filter the DataFrame to get rows with the specified \"Name\" values\n",
    "result = pbolymp[pbolymp['Name'].isin(names_to_filter)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39bd774f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "UKR    151\n",
       "USA     96\n",
       "JPN     84\n",
       "TUR     62\n",
       "SUI     56\n",
       "CHN     16\n",
       "PRK     11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afd7eaa",
   "metadata": {},
   "source": [
    "# Find names from USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea506b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = result[result['Country']=='USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "716b31d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['yul moldauer', 'yul kyung tae moldauer', 'curran phillips'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa['Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922c2f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
