{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cfd972e",
   "metadata": {},
   "source": [
    "# USA not likely to medal\n",
    "\n",
    "## Scaling no improvement \n",
    "\n",
    "## Feautre importance helped\n",
    "\n",
    "## Grid Search not needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "907456c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from mlxtend.preprocessing import minmax_scaling\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, fbeta_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74f86e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f41e4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Combine_Data/men/iaa_encoded.csv')\n",
    "iaaolymp = pd.read_csv('../../Combine_Data/men/iaa2024.csv')\n",
    "olymp = pd.read_csv('../../Combine_Data/men/encoded_m_olympics_iaa.csv')\n",
    "iaanames = pd.read_csv('../../Combine_Data/men/encoded_m_olympics_iaanames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9a2b513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>FX</th>\n",
       "      <th>PH</th>\n",
       "      <th>SR</th>\n",
       "      <th>VT</th>\n",
       "      <th>PB</th>\n",
       "      <th>HB</th>\n",
       "      <th>AA</th>\n",
       "      <th>year</th>\n",
       "      <th>medal</th>\n",
       "      <th>Name</th>\n",
       "      <th>Nation</th>\n",
       "      <th>round_final</th>\n",
       "      <th>round_qual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.800</td>\n",
       "      <td>13.400</td>\n",
       "      <td>14.533</td>\n",
       "      <td>15.133</td>\n",
       "      <td>15.566</td>\n",
       "      <td>14.166</td>\n",
       "      <td>87.598</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>14.133</td>\n",
       "      <td>14.700</td>\n",
       "      <td>14.333</td>\n",
       "      <td>14.866</td>\n",
       "      <td>15.333</td>\n",
       "      <td>14.233</td>\n",
       "      <td>87.598</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>14.733</td>\n",
       "      <td>13.566</td>\n",
       "      <td>14.500</td>\n",
       "      <td>14.766</td>\n",
       "      <td>14.866</td>\n",
       "      <td>13.900</td>\n",
       "      <td>86.331</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1</td>\n",
       "      <td>245</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>13.633</td>\n",
       "      <td>14.766</td>\n",
       "      <td>13.900</td>\n",
       "      <td>14.533</td>\n",
       "      <td>14.800</td>\n",
       "      <td>14.266</td>\n",
       "      <td>85.898</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>14.400</td>\n",
       "      <td>14.300</td>\n",
       "      <td>14.166</td>\n",
       "      <td>14.600</td>\n",
       "      <td>15.441</td>\n",
       "      <td>12.366</td>\n",
       "      <td>85.273</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>78</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>37.0</td>\n",
       "      <td>14.050</td>\n",
       "      <td>10.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.600</td>\n",
       "      <td>12.650</td>\n",
       "      <td>12.750</td>\n",
       "      <td>63.850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.450</td>\n",
       "      <td>12.700</td>\n",
       "      <td>12.100</td>\n",
       "      <td>11.800</td>\n",
       "      <td>12.150</td>\n",
       "      <td>61.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>80</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>39.0</td>\n",
       "      <td>13.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.600</td>\n",
       "      <td>13.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.500</td>\n",
       "      <td>54.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>80</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>80</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>80</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank      FX      PH      SR      VT      PB      HB      AA    year  \\\n",
       "0     1.0  14.800  13.400  14.533  15.133  15.566  14.166  87.598  2018.0   \n",
       "1     2.0  14.133  14.700  14.333  14.866  15.333  14.233  87.598  2018.0   \n",
       "2     3.0  14.733  13.566  14.500  14.766  14.866  13.900  86.331  2018.0   \n",
       "3     4.0  13.633  14.766  13.900  14.533  14.800  14.266  85.898  2018.0   \n",
       "4     5.0  14.400  14.300  14.166  14.600  15.441  12.366  85.273  2018.0   \n",
       "..    ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "507  37.0  14.050  10.800   0.000  13.600  12.650  12.750  63.850     NaN   \n",
       "508  38.0   0.000  12.450  12.700  12.100  11.800  12.150  61.200     NaN   \n",
       "509  39.0  13.400   0.000  14.600  13.700   0.000  12.500  54.200     NaN   \n",
       "510  40.0   0.000  14.700   0.000   0.000   0.000   0.000  14.700     NaN   \n",
       "511  41.0   0.000  12.700   0.000   0.000   0.000   0.000  12.700     NaN   \n",
       "\n",
       "     medal  Name  Nation  round_final  round_qual  \n",
       "0        0    41      63         True       False  \n",
       "1        1   337      13         True       False  \n",
       "2        1   245      63         True       False  \n",
       "3        0   307      13         True       False  \n",
       "4        0   292      78         True       False  \n",
       "..     ...   ...     ...          ...         ...  \n",
       "507      0     7      80         True       False  \n",
       "508      0   159      80         True       False  \n",
       "509      0    18      80         True       False  \n",
       "510      0    16      80         True       False  \n",
       "511      0   113      80         True       False  \n",
       "\n",
       "[512 rows x 14 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9102c",
   "metadata": {},
   "source": [
    "# Drop Columns - View Feature Importance below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a924033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['year', 'Nation', 'round_final', 'round_qual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34be5ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0d87569",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50015196",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87dfd0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp=olymp.drop(columns=['year', 'Nation', 'round_final', 'round_qual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0e5ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp = olymp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65554850",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=110)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d081a12e",
   "metadata": {},
   "source": [
    "# Base line using ZeroR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84c24393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeroR Classifier\n",
      "Accuracy: 0.9753\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        79\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.98        81\n",
      "   macro avg       0.49      0.50      0.49        81\n",
      "weighted avg       0.95      0.98      0.96        81\n",
      "\n",
      "Confusion Matrix:\n",
      "[[79  0]\n",
      " [ 2  0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns=['medal'])  \n",
    "y = df['medal']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize  ZeroR classifier\n",
    "zero_r_clf = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "\n",
    "zero_r_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on  test data\n",
    "y_pred = zero_r_clf.predict(X_test)\n",
    "\n",
    "# Evaluate  model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"ZeroR Classifier\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ca58b",
   "metadata": {},
   "source": [
    "# Model Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8dd0525",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Random Forest\n",
      "Accuracy: 1.0000\n",
      "F2-Score: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        98\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       101\n",
      "   macro avg       1.00      1.00      1.00       101\n",
      "weighted avg       1.00      1.00      1.00       101\n",
      "\n",
      "Confusion Matrix:\n",
      "[[98  0]\n",
      " [ 0  3]]\n",
      "\n",
      "Classifier: AdaBoost\n",
      "Accuracy: 0.9703\n",
      "F2-Score: 0.3571\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        98\n",
      "           1       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.97       101\n",
      "   macro avg       0.74      0.66      0.69       101\n",
      "weighted avg       0.97      0.97      0.97       101\n",
      "\n",
      "Confusion Matrix:\n",
      "[[97  1]\n",
      " [ 2  1]]\n",
      "\n",
      "Classifier: SVM\n",
      "Accuracy: 0.9703\n",
      "F2-Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        98\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.97       101\n",
      "   macro avg       0.49      0.50      0.49       101\n",
      "weighted avg       0.94      0.97      0.96       101\n",
      "\n",
      "Confusion Matrix:\n",
      "[[98  0]\n",
      " [ 3  0]]\n",
      "\n",
      "Classifier: K-Nearest Neighbors\n",
      "Accuracy: 0.9703\n",
      "F2-Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        98\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.97       101\n",
      "   macro avg       0.49      0.50      0.49       101\n",
      "weighted avg       0.94      0.97      0.96       101\n",
      "\n",
      "Confusion Matrix:\n",
      "[[98  0]\n",
      " [ 3  0]]\n",
      "\n",
      "Classifier: Decision Tree\n",
      "Accuracy: 0.9802\n",
      "F2-Score: 0.6667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        98\n",
      "           1       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.98       101\n",
      "   macro avg       0.83      0.83      0.83       101\n",
      "weighted avg       0.98      0.98      0.98       101\n",
      "\n",
      "Confusion Matrix:\n",
      "[[97  1]\n",
      " [ 1  2]]\n",
      "\n",
      "Classifier: Naive Bayes\n",
      "Accuracy: 0.9703\n",
      "F2-Score: 0.8333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        98\n",
      "           1       0.50      1.00      0.67         3\n",
      "\n",
      "    accuracy                           0.97       101\n",
      "   macro avg       0.75      0.98      0.83       101\n",
      "weighted avg       0.99      0.97      0.98       101\n",
      "\n",
      "Confusion Matrix:\n",
      "[[95  3]\n",
      " [ 0  3]]\n",
      "\n",
      "Classifier: Neural Network\n",
      "Accuracy: 0.9703\n",
      "F2-Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        98\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.97       101\n",
      "   macro avg       0.49      0.50      0.49       101\n",
      "weighted avg       0.94      0.97      0.96       101\n",
      "\n",
      "Confusion Matrix:\n",
      "[[98  0]\n",
      " [ 3  0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Neural Network\": MLPClassifier(),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=110)\n",
    "\n",
    "# Iterate through each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    # Create a pipeline with StandardScaler for classifiers that require it\n",
    "    if name in [\"SVM\", \"K-Nearest Neighbors\", \"Neural Network\"]:\n",
    "        clf = make_pipeline(StandardScaler(), clf)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    beta = 2\n",
    "    f2_score = fbeta_score(y_test, y_pred, beta=beta)\n",
    "\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "        \"f2_score\": f2_score,\n",
    "    }\n",
    "    \n",
    "for name, result in results.items():\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"F2-Score: {result['f2_score']:.4f}\")\n",
    "    print(f\"Classification Report:\\n{result['classification_report']}\")\n",
    "    print(f\"Confusion Matrix:\\n{result['confusion_matrix']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5763ab",
   "metadata": {},
   "source": [
    "# Grid Search - no imporovement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1462e3",
   "metadata": {},
   "source": [
    "## Grid Search with k-folds cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08bc9799",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Best Hyperparameters: {'base_estimator__max_depth': 3, 'base_estimator__min_samples_leaf': 4, 'base_estimator__min_samples_split': 2, 'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        31\n",
      "   macro avg       1.00      1.00      1.00        31\n",
      "weighted avg       1.00      1.00      1.00        31\n",
      "\n",
      "Confusion Matrix:\n",
      "[[30  0]\n",
      " [ 0  1]]\n",
      "\n",
      "Fold 2\n",
      "Best Hyperparameters: {'base_estimator__max_depth': 3, 'base_estimator__min_samples_leaf': 4, 'base_estimator__min_samples_split': 2, 'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        31\n",
      "   macro avg       1.00      1.00      1.00        31\n",
      "weighted avg       1.00      1.00      1.00        31\n",
      "\n",
      "Confusion Matrix:\n",
      "[[30  0]\n",
      " [ 0  1]]\n",
      "\n",
      "Fold 3\n",
      "Best Hyperparameters: {'base_estimator__max_depth': 3, 'base_estimator__min_samples_leaf': 4, 'base_estimator__min_samples_split': 2, 'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Accuracy: 0.9677\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        30\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.97        31\n",
      "   macro avg       0.75      0.98      0.82        31\n",
      "weighted avg       0.98      0.97      0.97        31\n",
      "\n",
      "Confusion Matrix:\n",
      "[[29  1]\n",
      " [ 0  1]]\n",
      "\n",
      "Fold 4\n",
      "Best Hyperparameters: {'base_estimator__max_depth': 3, 'base_estimator__min_samples_leaf': 4, 'base_estimator__min_samples_split': 2, 'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Confusion Matrix:\n",
      "[[30]]\n",
      "\n",
      "Fold 5\n",
      "Best Hyperparameters: {'base_estimator__max_depth': 3, 'base_estimator__min_samples_leaf': 4, 'base_estimator__min_samples_split': 2, 'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Confusion Matrix:\n",
      "[[30]]\n",
      "\n",
      "Fold 6\n",
      "Best Hyperparameters: {'base_estimator__max_depth': 3, 'base_estimator__min_samples_leaf': 4, 'base_estimator__min_samples_split': 2, 'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Confusion Matrix:\n",
      "[[30]]\n",
      "\n",
      "Fold 7\n",
      "Best Hyperparameters: {'base_estimator__max_depth': 3, 'base_estimator__min_samples_leaf': 4, 'base_estimator__min_samples_split': 2, 'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Confusion Matrix:\n",
      "[[30]]\n",
      "\n",
      "Fold 8\n",
      "Best Hyperparameters: {'base_estimator__max_depth': 3, 'base_estimator__min_samples_leaf': 4, 'base_estimator__min_samples_split': 2, 'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Accuracy: 0.9667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        29\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.48      0.50      0.49        30\n",
      "weighted avg       0.93      0.97      0.95        30\n",
      "\n",
      "Confusion Matrix:\n",
      "[[29  0]\n",
      " [ 1  0]]\n",
      "\n",
      "Fold 9\n",
      "Best Hyperparameters: {'base_estimator__max_depth': 3, 'base_estimator__min_samples_leaf': 4, 'base_estimator__min_samples_split': 2, 'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Accuracy: 0.9667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        29\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.48      0.50      0.49        30\n",
      "weighted avg       0.93      0.97      0.95        30\n",
      "\n",
      "Confusion Matrix:\n",
      "[[29  0]\n",
      " [ 1  0]]\n",
      "\n",
      "Fold 10\n",
      "Best Hyperparameters: {'base_estimator__max_depth': 3, 'base_estimator__min_samples_leaf': 4, 'base_estimator__min_samples_split': 2, 'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        29\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Confusion Matrix:\n",
      "[[29  0]\n",
      " [ 0  1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=110)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  \n",
    "    'learning_rate': [0.1, 0.2, 0.3], \n",
    "    'base_estimator__max_depth': [2, 3, 4],\n",
    "    'base_estimator__min_samples_split': [2, 5, 10],\n",
    "    'base_estimator__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the AdaBoost classifier with the best hyperparameters\n",
    "base_classifier = DecisionTreeClassifier()\n",
    "best_clf = AdaBoostClassifier(base_classifier)\n",
    "\n",
    "# Initialize StratifiedKFold for k-fold cross-validation\n",
    "k_folds = 10\n",
    "stratified_kfold = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Create the grid search object with StratifiedKFold\n",
    "grid_search = GridSearchCV(best_clf, param_grid, cv=stratified_kfold, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator from the grid search\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Iterate over folds for evaluation\n",
    "for fold, (train_index, test_index) in enumerate(stratified_kfold.split(X_train, y_train)):\n",
    "    print(f\"\\nFold {fold + 1}\")\n",
    "\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    # Train the model for this fold\n",
    "    best_clf.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions on the validation data for this fold\n",
    "    y_pred = best_clf.predict(X_val_fold)\n",
    "\n",
    "    # Evaluate the model's performance for this fold\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "    report = classification_report(y_val_fold, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_val_fold, y_pred)\n",
    "\n",
    "    print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Classification Report:\\n{report}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219e975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab3a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a50afc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier with Grid Search\n",
      "Best Hyperparameters: {'base_estimator__max_depth': 2, 'learning_rate': 0.2, 'n_estimators': 50}\n",
      "Accuracy: 0.9802\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        98\n",
      "           1       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.98       101\n",
      "   macro avg       0.83      0.83      0.83       101\n",
      "weighted avg       0.98      0.98      0.98       101\n",
      "\n",
      "Confusion Matrix:\n",
      "[[97  1]\n",
      " [ 1  2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=110)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50],  \n",
    "    'learning_rate': [0.2], \n",
    "    'base_estimator__max_depth': [2] \n",
    "}\n",
    "\n",
    "# Initialize the AdaBoost classifier with the best hyperparameters\n",
    "base_classifier = DecisionTreeClassifier()\n",
    "best_clf = AdaBoostClassifier(base_classifier)\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(best_clf, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator from the grid search\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"AdaBoost Classifier with Grid Search\")\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483b0fa6",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c455064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "Rank: 0.0000\n",
      "FX: 0.0200\n",
      "PH: 0.0000\n",
      "SR: 0.0200\n",
      "VT: 0.1600\n",
      "PB: 0.3000\n",
      "HB: 0.1600\n",
      "AA: 0.1600\n",
      "Name: 0.1800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "# Initialize the AdaBoost classifier\n",
    "clf = AdaBoostClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Print feature importances\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in zip(X.columns, feature_importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cad0c48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(X.columns, feature_importances, color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('AdaBoost Classifier - Feature Importances')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f74e7",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "181b93a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        98\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       101\n",
      "   macro avg       1.00      1.00      1.00       101\n",
      "weighted avg       1.00      1.00      1.00       101\n",
      "\n",
      "Confusion Matrix:\n",
      "[[98  0]\n",
      " [ 0  3]]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['medal'])  # Features\n",
    "y = df['medal']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=110)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Random Forest Classifier\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac6c766",
   "metadata": {},
   "source": [
    "# Model Trained earlier, now using 2023/2022 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba343e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp = pd.read_csv('../../Combine_Data/men/encoded_m_olympics_iaa.csv')\n",
    "olymp=olymp.drop(columns=['year', 'Nation', 'round_final',\n",
    "       'round_qual'])\n",
    "olymp = olymp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be1b829c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = rf_clf.predict(olymp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fee29ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds  = pd.Series(y_pred)\n",
    "olymp['ypred']=ypreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b591b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ypred\n",
       "0.0    413\n",
       "1.0      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olymp['ypred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60dc07f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = olymp[olymp['ypred'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6021d43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([411,  96])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def4ae8f",
   "metadata": {},
   "source": [
    "# iaanames used to match encoded names with actual names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d31f72cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_encoded_values = [411]\n",
    "\n",
    "# Filter the DataFrame to get corresponding values\n",
    "result = iaanames.loc[iaanames['Name_encoded'].isin(name_encoded_values), 'Athlete']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcd41583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['zhang boheng'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a471da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
