{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b95d87b7-37ca-4721-a305-9776431a2a57",
   "metadata": {},
   "source": [
    "used adaboost with grid search, k-folds validation, and feature importance\n",
    "# ['landon simpson', 'shane wiskus'] - both no good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a3fcafc4-cc48-4f0e-aa75-44eee217d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# from mlxtend.preprocessing import minmax_scaling\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, fbeta_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, make_scorer, fbeta_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7b0838e8-1343-425f-a13d-a8614ff856ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0a60cddc-4aea-48da-9d1c-bb680c85360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Combine_Data/men/ph_encoded.csv')\n",
    "olymp = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_ph.csv')\n",
    "phnames = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_phnames.csv')\n",
    "pholymp = pd.read_csv('../../Data/cleandata22-23/men22_23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "086c1313-7d4a-4abf-97be-52f3d8e29983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olymp.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ae45672e-5a38-4b41-b110-5164112fd508",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp = olymp.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b5a02744-5268-4fac-89c9-7666a9825a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=[ 'round_qual','round_final', 'Nation', 'ND'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "dadc6d96-3788-4fb4-85f0-1d4eb35d1576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>Total</th>\n",
       "      <th>year</th>\n",
       "      <th>medal</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.766</td>\n",
       "      <td>15.266</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.733</td>\n",
       "      <td>15.233</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.166</td>\n",
       "      <td>14.666</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.600</td>\n",
       "      <td>13.700</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7.233</td>\n",
       "      <td>13.133</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>24</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.850</td>\n",
       "      <td>11.650</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>25</td>\n",
       "      <td>4.9</td>\n",
       "      <td>7.850</td>\n",
       "      <td>12.750</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>25</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.600</td>\n",
       "      <td>11.500</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>26</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.300</td>\n",
       "      <td>10.800</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>26</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.700</td>\n",
       "      <td>12.900</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>535 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank    D      E   Total  year  medal  Name\n",
       "0       1  6.5  8.766  15.266  2019      1   173\n",
       "1       2  6.5  8.733  15.233  2019      0   319\n",
       "2       3  6.5  8.166  14.666  2019      0   303\n",
       "3       4  6.1  7.600  13.700  2019      0   297\n",
       "4       5  5.9  7.233  13.133  2019      0    98\n",
       "..    ...  ...    ...     ...   ...    ...   ...\n",
       "530    24  4.8  6.850  11.650  2020      0   130\n",
       "531    25  4.9  7.850  12.750  2020      0   203\n",
       "532    25  4.9  6.600  11.500  2020      0   203\n",
       "533    26  5.5  5.300  10.800  2020      0    10\n",
       "534    26  5.2  7.700  12.900  2020      0    10\n",
       "\n",
       "[535 rows x 7 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3dc682cc-8a32-4008-a3c7-630d7bc990bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 535 entries, 0 to 534\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Rank    535 non-null    int64  \n",
      " 1   D       535 non-null    float64\n",
      " 2   E       535 non-null    float64\n",
      " 3   Total   535 non-null    float64\n",
      " 4   year    535 non-null    int64  \n",
      " 5   medal   535 non-null    int64  \n",
      " 6   Name    535 non-null    int64  \n",
      "dtypes: float64(3), int64(4)\n",
      "memory usage: 29.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea427a4-63c0-4323-b1f9-c01eb653cb03",
   "metadata": {},
   "source": [
    "# Base line using ZeroR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e4076a95-26b1-48c6-a24c-e940137baa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeroR Classifier\n",
      "Accuracy: 0.9774\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       173\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.98       177\n",
      "   macro avg       0.49      0.50      0.49       177\n",
      "weighted avg       0.96      0.98      0.97       177\n",
      "\n",
      "Confusion Matrix:\n",
      "[[173   0]\n",
      " [  4   0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns=['medal'])  \n",
    "y = df['medal']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=90)\n",
    "\n",
    "# Initialize  ZeroR classifier\n",
    "zero_r_clf = DummyClassifier(strategy='most_frequent', random_state=90)\n",
    "\n",
    "zero_r_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on  test data\n",
    "y_pred = zero_r_clf.predict(X_test)\n",
    "\n",
    "# Evaluate  model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"ZeroR Classifier\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835c306a-fabf-43b4-b0c6-ddaea35c6c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dee249f-2e5f-4792-a70a-13f7ee93d713",
   "metadata": {},
   "source": [
    "# Model Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "46f19700-e382-46d2-9d12-d3cd0f04a22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier: Random Forest\n",
      "Accuracy: 0.9831\n",
      "F2-Score: 0.2941\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       173\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.98       177\n",
      "   macro avg       0.99      0.62      0.70       177\n",
      "weighted avg       0.98      0.98      0.98       177\n",
      "\n",
      "Confusion Matrix:\n",
      "[[173   0]\n",
      " [  3   1]]\n",
      "\n",
      "Classifier: AdaBoost\n",
      "Accuracy: 1.0000\n",
      "F2-Score: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       173\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00       177\n",
      "   macro avg       1.00      1.00      1.00       177\n",
      "weighted avg       1.00      1.00      1.00       177\n",
      "\n",
      "Confusion Matrix:\n",
      "[[173   0]\n",
      " [  0   4]]\n",
      "\n",
      "Classifier: Gradient Boosting\n",
      "Accuracy: 0.9944\n",
      "F2-Score: 0.9524\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       173\n",
      "           1       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.99       177\n",
      "   macro avg       0.90      1.00      0.94       177\n",
      "weighted avg       1.00      0.99      0.99       177\n",
      "\n",
      "Confusion Matrix:\n",
      "[[172   1]\n",
      " [  0   4]]\n",
      "\n",
      "Classifier: XGBoost\n",
      "Accuracy: 0.9944\n",
      "F2-Score: 0.7895\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       173\n",
      "           1       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.99       177\n",
      "   macro avg       1.00      0.88      0.93       177\n",
      "weighted avg       0.99      0.99      0.99       177\n",
      "\n",
      "Confusion Matrix:\n",
      "[[173   0]\n",
      " [  1   3]]\n",
      "\n",
      "Classifier: Voting Classifier (Hard)\n",
      "Accuracy: 0.9944\n",
      "F2-Score: 0.7895\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       173\n",
      "           1       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.99       177\n",
      "   macro avg       1.00      0.88      0.93       177\n",
      "weighted avg       0.99      0.99      0.99       177\n",
      "\n",
      "Confusion Matrix:\n",
      "[[173   0]\n",
      " [  1   3]]\n",
      "\n",
      "Classifier: Voting Classifier (Soft)\n",
      "Accuracy: 1.0000\n",
      "F2-Score: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       173\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00       177\n",
      "   macro avg       1.00      1.00      1.00       177\n",
      "weighted avg       1.00      1.00      1.00       177\n",
      "\n",
      "Confusion Matrix:\n",
      "[[173   0]\n",
      " [  0   4]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, fbeta_score\n",
    "\n",
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=90)\n",
    "\n",
    "# Initialize classifiers\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "adaboost = AdaBoostClassifier(random_state=42)\n",
    "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
    "xgboost = XGBClassifier(random_state=42)\n",
    "\n",
    "# Hard Voting Classifier\n",
    "voting_classifier_hard = VotingClassifier(estimators=[\n",
    "    ('random_forest', random_forest),\n",
    "    ('adaboost', adaboost),\n",
    "    ('gradient_boosting', gradient_boosting),\n",
    "    ('xgboost', xgboost)\n",
    "], voting='hard')\n",
    "\n",
    "# Soft Voting Classifier\n",
    "voting_classifier_soft = VotingClassifier(estimators=[\n",
    "    ('random_forest', random_forest),\n",
    "    ('adaboost', adaboost),\n",
    "    ('gradient_boosting', gradient_boosting),\n",
    "    ('xgboost', xgboost)\n",
    "], voting='soft')\n",
    "\n",
    "# Train the classifiers\n",
    "classifiers = {\n",
    "    'Random Forest': random_forest,\n",
    "    'AdaBoost': adaboost,\n",
    "    'Gradient Boosting': gradient_boosting,\n",
    "    'XGBoost': xgboost,\n",
    "    'Voting Classifier (Hard)': voting_classifier_hard,\n",
    "    'Voting Classifier (Soft)': voting_classifier_soft\n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f2_score = fbeta_score(y_test, y_pred, beta=2)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\nClassifier: {name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F2-Score: {f2_score:.4f}\")\n",
    "    print(f\"Classification Report:\\n{report}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0cbf356f-ef38-4bfc-aeaf-0c085d41ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.metrics import accuracy_score, fbeta_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# X = df.drop(columns=['medal'])\n",
    "# y = df['medal']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.23, random_state=90)\n",
    "\n",
    "# # Example AdaBoost Classifier\n",
    "# ada_clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "# ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# # Example XGBoost Classifier\n",
    "# xgb_clf = XGBClassifier(n_estimators=50, random_state=42)\n",
    "# xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# # Example Soft Voting Classifier\n",
    "# soft_voting_clf = VotingClassifier(\n",
    "#     estimators=[('ada', ada_clf), ('xgb', xgb_clf)],\n",
    "#     voting='soft'\n",
    "# )\n",
    "# soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the models\n",
    "# models = {'AdaBoost': ada_clf, 'XGBoost': xgb_clf, 'Soft Voting': soft_voting_clf}\n",
    "\n",
    "# for name, model in models.items():\n",
    "#     y_pred = model.predict(X_test)\n",
    "    \n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     f2_score = fbeta_score(y_test, y_pred, beta=2)\n",
    "#     report = classification_report(y_test, y_pred)\n",
    "#     conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#     print(f\"Classifier: {name}\")\n",
    "#     print(f\"Accuracy: {accuracy:.4f}\")\n",
    "#     print(f\"F2-Score: {f2_score:.4f}\")\n",
    "#     print(f\"Classification Report:\\n{report}\")\n",
    "#     print(f\"Confusion Matrix:\\n{conf_matrix}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0311980f-5f4d-463a-a5cb-4f8742cacbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import VotingClassifier\n",
    "# from sklearn.base import clone\n",
    "\n",
    "\n",
    "# # Create a list of base classifiers\n",
    "# classifiers = [\n",
    "#     ('AdaBoost', clone(ada_clf)),\n",
    "#     ('XGBoost', clone(xgb_clf)),\n",
    "#     ('SoftVoting', clone(soft_voting_clf))\n",
    "# ]\n",
    "\n",
    "# # Create the ensemble model (Voting Classifier)\n",
    "# ensemble_model = VotingClassifier(estimators=classifiers, voting='soft')\n",
    "\n",
    "# # Train the ensemble model\n",
    "# ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# # Predictions on the test set\n",
    "# ensemble_predictions = ensemble_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the ensemble model\n",
    "# ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "# ensemble_f2_score = fbeta_score(y_test, ensemble_predictions, beta=2)\n",
    "# ensemble_report = classification_report(y_test, ensemble_predictions)\n",
    "# ensemble_conf_matrix = confusion_matrix(y_test, ensemble_predictions)\n",
    "\n",
    "# # Display results for the ensemble model\n",
    "# print(\"\\nEnsemble Model (AdaBoost, XGBoost, and Soft Voting)\")\n",
    "# print(f\"Accuracy: {ensemble_accuracy:.4f}\")\n",
    "# print(f\"F2-Score: {ensemble_f2_score:.4f}\")\n",
    "# print(f\"Classification Report:\\n{ensemble_report}\")\n",
    "# print(f\"Confusion Matrix:\\n{ensemble_conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cf3bc686-7764-4860-9d2f-3ad5369e138d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stacking Model (AdaBoost, XGBoost, KNN, Decision Tree with RandomForest meta-model)\n",
      "Accuracy: 1.0000\n",
      "F2-Score: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       122\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       124\n",
      "   macro avg       1.00      1.00      1.00       124\n",
      "weighted avg       1.00      1.00      1.00       124\n",
      "\n",
      "Confusion Matrix:\n",
      "[[122   0]\n",
      " [  0   2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score, fbeta_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.23, random_state=90)\n",
    "\n",
    "# Create base models\n",
    "ada_clf = AdaBoostClassifier(n_estimators=50, learning_rate=0.1)\n",
    "xgb_clf = XGBClassifier(n_estimators=50, learning_rate=0.1, max_depth=3)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# Create the ensemble model (Stacking Classifier)\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('AdaBoost', clone(ada_clf)),\n",
    "        ('XGBoost', clone(xgb_clf)),\n",
    "        ('KNN', clone(knn_clf)),\n",
    "        ('DecisionTree', clone(dt_clf))\n",
    "    ],\n",
    "    final_estimator=RandomForestClassifier(),  # Meta-model\n",
    "    stack_method='auto',  # Auto mode for the meta-model fitting strategy\n",
    "    cv=11  # Number of cross-validation folds for training base models\n",
    ")\n",
    "\n",
    "# Train the stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "stacking_predictions = stacking_model.predict(X_test)\n",
    "\n",
    "# Evaluate the stacking model\n",
    "stacking_accuracy = accuracy_score(y_test, stacking_predictions)\n",
    "stacking_f2_score = fbeta_score(y_test, stacking_predictions, beta=2)\n",
    "stacking_report = classification_report(y_test, stacking_predictions)\n",
    "stacking_conf_matrix = confusion_matrix(y_test, stacking_predictions)\n",
    "\n",
    "# Display results for the stacking model\n",
    "print(\"\\nStacking Model (AdaBoost, XGBoost, KNN, Decision Tree with RandomForest meta-model)\")\n",
    "print(f\"Accuracy: {stacking_accuracy:.4f}\")\n",
    "print(f\"F2-Score: {stacking_f2_score:.4f}\")\n",
    "print(f\"Classification Report:\\n{stacking_report}\")\n",
    "print(f\"Confusion Matrix:\\n{stacking_conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba4ffb-8d8c-42e2-8b73-40cb50f418a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcbde39-15cf-49b4-b263-57e0c7606fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "11557c53-d747-4846-827c-d84d22df1857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Classifier: Random Forest\n",
      "Best Hyperparameters: {}\n",
      "Accuracy: 1.0000\n",
      "F2-Score: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       122\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       124\n",
      "   macro avg       1.00      1.00      1.00       124\n",
      "weighted avg       1.00      1.00      1.00       124\n",
      "\n",
      "Confusion Matrix:\n",
      "[[122   0]\n",
      " [  0   2]]\n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Classifier: AdaBoost\n",
      "Best Hyperparameters: {}\n",
      "Accuracy: 1.0000\n",
      "F2-Score: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       122\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       124\n",
      "   macro avg       1.00      1.00      1.00       124\n",
      "weighted avg       1.00      1.00      1.00       124\n",
      "\n",
      "Confusion Matrix:\n",
      "[[122   0]\n",
      " [  0   2]]\n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Classifier: SVM\n",
      "Best Hyperparameters: {}\n",
      "Accuracy: 0.9839\n",
      "F2-Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       122\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.98       124\n",
      "   macro avg       0.49      0.50      0.50       124\n",
      "weighted avg       0.97      0.98      0.98       124\n",
      "\n",
      "Confusion Matrix:\n",
      "[[122   0]\n",
      " [  2   0]]\n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Classifier: K-Nearest Neighbors\n",
      "Best Hyperparameters: {}\n",
      "Accuracy: 1.0000\n",
      "F2-Score: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       122\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       124\n",
      "   macro avg       1.00      1.00      1.00       124\n",
      "weighted avg       1.00      1.00      1.00       124\n",
      "\n",
      "Confusion Matrix:\n",
      "[[122   0]\n",
      " [  0   2]]\n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Classifier: Decision Tree\n",
      "Best Hyperparameters: {}\n",
      "Accuracy: 0.9758\n",
      "F2-Score: 0.4545\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       122\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       124\n",
      "   macro avg       0.66      0.74      0.69       124\n",
      "weighted avg       0.98      0.98      0.98       124\n",
      "\n",
      "Confusion Matrix:\n",
      "[[120   2]\n",
      " [  1   1]]\n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Classifier: Naive Bayes\n",
      "Best Hyperparameters: {}\n",
      "Accuracy: 0.9839\n",
      "F2-Score: 0.8333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       122\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.98       124\n",
      "   macro avg       0.75      0.99      0.83       124\n",
      "weighted avg       0.99      0.98      0.99       124\n",
      "\n",
      "Confusion Matrix:\n",
      "[[120   2]\n",
      " [  0   2]]\n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Classifier: Neural Network\n",
      "Best Hyperparameters: {}\n",
      "Accuracy: 0.9839\n",
      "F2-Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       122\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.98       124\n",
      "   macro avg       0.49      0.50      0.50       124\n",
      "weighted avg       0.97      0.98      0.98       124\n",
      "\n",
      "Confusion Matrix:\n",
      "[[122   0]\n",
      " [  2   0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "# CHANGED RANDOM STATE TO HAVE A LARGER NUMBER OF VALUES IN TEST DF\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.23, random_state=90)\n",
    "\n",
    "# Initialize classifiers with default hyperparameters\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Neural Network\": MLPClassifier(),\n",
    "}\n",
    "\n",
    "# Create a dictionary to store the best hyperparameters for each classifier\n",
    "best_params = {}\n",
    "\n",
    "# Iterate through each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    # Create a pipeline with StandardScaler for classifiers that require it\n",
    "    if name in [\"SVM\", \"K-Nearest Neighbors\", \"Neural Network\"]:\n",
    "        pipeline = make_pipeline(StandardScaler(), clf)\n",
    "    else:\n",
    "        pipeline = clf\n",
    "\n",
    "    # Define parameter grid for hyperparameter tuning\n",
    "    param_grid = {}  # Add hyperparameters and their possible values to tune\n",
    "\n",
    "    # Initialize StratifiedKFold for cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Use GridSearchCV for hyperparameter tuning\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        scoring={'accuracy': 'accuracy', 'f2_score': make_scorer(fbeta_score, beta=2)},\n",
    "        refit='accuracy',  # Choose the metric to optimize\n",
    "        cv=cv,\n",
    "        n_jobs=-1,  # Use all available CPUs\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Fit the model to the training data with hyperparameter tuning\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters and store them\n",
    "    best_params[name] = grid_search.best_params_\n",
    "\n",
    "    # Make predictions on the test data using the best model\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(f\"Best Hyperparameters: {best_params[name]}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F2-Score: {fbeta_score(y_test, y_pred, beta=2):.4f}\")\n",
    "    print(f\"Classification Report:\\n{report}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633fd96b-b6a5-4357-86e0-36f535046845",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3847a3bd-7cf9-468b-a41a-6c6cd5c5c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# y = df['medal']\n",
    "# X = df.drop(columns=['medal'])\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.13, random_state=9)\n",
    "\n",
    "# # Initialize the AdaBoost classifier\n",
    "# clf = AdaBoostClassifier()\n",
    "\n",
    "# # Fit the model to the training data\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Extract feature importances\n",
    "# feature_importances = clf.feature_importances_\n",
    "\n",
    "# # Print feature importances\n",
    "# print(\"Feature Importances:\")\n",
    "# for feature, importance in zip(X.columns, feature_importances):\n",
    "#     print(f\"{feature}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "93d283c2-0ef1-48cd-8bea-8703ff77ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# feature_importances = clf.feature_importances_\n",
    "\n",
    "# # Plot feature importances\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.barh(X.columns, feature_importances, color='skyblue')\n",
    "# plt.xlabel('Feature Importance')\n",
    "# plt.title('AdaBoost Classifier - Feature Importances')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadfb2dc-a15c-4067-9ff9-4e1b5126bae2",
   "metadata": {},
   "source": [
    "# # Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "03f9f8a7-8540-4f45-b2d5-963fe68fbd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Hyperparameters: {'learning_rate': 0.5, 'n_estimators': 20}\n",
      "Accuracy: 1.0000\n",
      "F2-Score: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       122\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       124\n",
      "   macro avg       1.00      1.00      1.00       124\n",
      "weighted avg       1.00      1.00      1.00       124\n",
      "\n",
      "Confusion Matrix:\n",
      "[[122   0]\n",
      " [  0   2]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, make_scorer, fbeta_score\n",
    "\n",
    "# Set up your X and y\n",
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "# CHANGED RANDOM STATE TO HAVE A LARGER NUMBER OF VALUES IN TEST DF\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.23, random_state=90)\n",
    "\n",
    "# Define the AdaBoostClassifier\n",
    "adaboost_clf = AdaBoostClassifier()\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [20, 23, 25, 27, 30],\n",
    "    'learning_rate': [.031, .45, .5, .55],\n",
    "    # Add other hyperparameters and their possible values here\n",
    "}\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(\n",
    "    adaboost_clf,\n",
    "    param_grid,\n",
    "    scoring={'accuracy': 'accuracy', 'f2_score': make_scorer(fbeta_score, beta=2)},\n",
    "    refit= 'f2_score',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,  # Use all available CPUs\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model to the training data with hyperparameter tuning\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F2-Score: {fbeta_score(y_test, y_pred, beta=2):.4f}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2ada39-3dfe-423a-8984-dbe44b7e7fb9",
   "metadata": {},
   "source": [
    "# Model Trained Above, now using 2023/2022 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "19f631e0-aeb8-4590-a496-b85dbda22152",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_ph.csv')\n",
    "olymp = olymp.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a2d1fa63-dc1b-483a-adea-861e38795de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp.rename(columns={'D Score': 'D', 'E Score': 'E',\n",
    "                     'Pen.': 'ND', 'nation': 'Nation'}, inplace=True)\n",
    "olymp=olymp.drop(columns=['round_TeamFinal', 'round_AAfinal', \n",
    "                          'round_TeamQual', 'ND', 'round_qual','round_final', 'Nation' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6058932d-182c-4c18-96a2-b2a7b0880861",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predz = grid_search.predict(olymp)\n",
    "\n",
    "# y_predz = ensemble_model.predict(olymp)\n",
    "\n",
    "# y_predz = stacking_model.predict(olymp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "98bf350e-f0b5-4ef0-9ca9-fe34ae843fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds  = pd.Series(y_predz)\n",
    "olymp['ypredz']=ypreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "01f21148-c73b-4420-8165-0140055b0275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2501\n",
       "1.0       3\n",
       "Name: ypredz, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olymp['ypredz'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1d6f6078-44e9-4c38-97ea-c9a76d5e79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = olymp[olymp['ypredz'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "02bdc5ca-8a72-4347-9d11-ed71cb6c5f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([419, 259])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9265a43d-e672-4868-91d1-cad3150c9a3d",
   "metadata": {},
   "source": [
    "# phnames used to match encoded names with actual names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "793b3806-c67a-48c8-8b36-b6bb68d0c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_encoded_values = [185, 163]\n",
    "\n",
    "name_encoded_values = [419, 259]\n",
    "# Filter the DataFrame to get the corresponding \"Name\" values\n",
    "result = phnames.loc[phnames['Name_encoded'].isin(name_encoded_values), 'Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7828cbd1-e5c8-43c4-b4ba-5d2a6b5e0204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['loran de munck', 'harald wibye'], dtype=object)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138185bc-f953-42c1-a862-1c0396fce639",
   "metadata": {},
   "source": [
    "# pholymp used to get country info from name list above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "012926c0-6864-4fc0-bd06-ec71c5ad3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pholymp[\"Name\"]=pholymp[\"Name\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a9d8fe19-5fb8-4bde-b760-04e13e74f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_filter =['loran de munck', 'harald wibye']\n",
    "# Filter the DataFrame to get rows with the specified \"Name\" values\n",
    "result = pholymp[pholymp['Name'].isin(names_to_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f5812dab-066f-4de8-81b1-e67babe49e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOR    35\n",
       "NED    25\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc194f-0132-42ca-aeed-af9a6d32da58",
   "metadata": {},
   "source": [
    "# Find names from USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8abce738-12d6-4a96-8d72-1697417658c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "usas=result[result['Country']=='USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e358e16f-65fe-48e0-86b6-196b30769068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usas['Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c700a-bc16-4955-9b68-7d7192b6d160",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
