{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a0abe07",
   "metadata": {},
   "source": [
    "# yul moldauer and curran phillips in Parallel Bars\n",
    "\n",
    "## SWcaling - no improvement\n",
    "## GirdSearch used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e8f2443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from mlxtend.preprocessing import minmax_scaling\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, fbeta_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55327fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b94c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Combine_Data/men/pb_encoded.csv')\n",
    "olymp = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_pb.csv')\n",
    "pbnames = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_pbnames.csv')\n",
    "pbolymp = pd.read_csv('../../Data/cleandata22-23/men22_23.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dffaf40",
   "metadata": {},
   "source": [
    "# Base line using ZeroR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15cdb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeroR Classifier\n",
      "Accuracy: 0.9689\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       156\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.97       161\n",
      "   macro avg       0.48      0.50      0.49       161\n",
      "weighted avg       0.94      0.97      0.95       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[156   0]\n",
      " [  5   0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns=['medal'])  \n",
    "y = df['medal']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=9)\n",
    "\n",
    "# Initialize  ZeroR classifier\n",
    "zero_r_clf = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "\n",
    "zero_r_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on  test data\n",
    "y_pred = zero_r_clf.predict(X_test)\n",
    "\n",
    "# Evaluate  model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"ZeroR Classifier\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e71d22f",
   "metadata": {},
   "source": [
    "# Model Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1614f56a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Logistic Regression\n",
      "Accuracy: 0.9627\n",
      "F2-Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       156\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.96       161\n",
      "   macro avg       0.48      0.50      0.49       161\n",
      "weighted avg       0.94      0.96      0.95       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[155   1]\n",
      " [  5   0]]\n",
      "\n",
      "Classifier: XGBoost\n",
      "Accuracy: 0.9752\n",
      "F2-Score: 0.4348\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       156\n",
      "           1       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.98       161\n",
      "   macro avg       0.82      0.70      0.74       161\n",
      "weighted avg       0.97      0.98      0.97       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[155   1]\n",
      " [  3   2]]\n",
      "\n",
      "Classifier: Random Forest\n",
      "Accuracy: 0.9752\n",
      "F2-Score: 0.2381\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       156\n",
      "           1       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           0.98       161\n",
      "   macro avg       0.99      0.60      0.66       161\n",
      "weighted avg       0.98      0.98      0.97       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[156   0]\n",
      " [  4   1]]\n",
      "\n",
      "Classifier: AdaBoost\n",
      "Accuracy: 0.9876\n",
      "F2-Score: 0.6522\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       156\n",
      "           1       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.99       161\n",
      "   macro avg       0.99      0.80      0.87       161\n",
      "weighted avg       0.99      0.99      0.99       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[156   0]\n",
      " [  2   3]]\n",
      "\n",
      "Classifier: SVM\n",
      "Accuracy: 0.9689\n",
      "F2-Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       156\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.97       161\n",
      "   macro avg       0.48      0.50      0.49       161\n",
      "weighted avg       0.94      0.97      0.95       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[156   0]\n",
      " [  5   0]]\n",
      "\n",
      "Classifier: K-Nearest Neighbors\n",
      "Accuracy: 0.9689\n",
      "F2-Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       156\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.97       161\n",
      "   macro avg       0.48      0.50      0.49       161\n",
      "weighted avg       0.94      0.97      0.95       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[156   0]\n",
      " [  5   0]]\n",
      "\n",
      "Classifier: Decision Tree\n",
      "Accuracy: 0.9938\n",
      "F2-Score: 0.9615\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       156\n",
      "           1       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.99       161\n",
      "   macro avg       0.92      1.00      0.95       161\n",
      "weighted avg       0.99      0.99      0.99       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[155   1]\n",
      " [  0   5]]\n",
      "\n",
      "Classifier: Naive Bayes\n",
      "Accuracy: 0.7702\n",
      "F2-Score: 0.4032\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.87       156\n",
      "           1       0.12      1.00      0.21         5\n",
      "\n",
      "    accuracy                           0.77       161\n",
      "   macro avg       0.56      0.88      0.54       161\n",
      "weighted avg       0.97      0.77      0.85       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[119  37]\n",
      " [  0   5]]\n",
      "\n",
      "Classifier: Neural Network\n",
      "Accuracy: 0.9689\n",
      "F2-Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       156\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.97       161\n",
      "   macro avg       0.48      0.50      0.49       161\n",
      "weighted avg       0.94      0.97      0.95       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[156   0]\n",
      " [  5   0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, fbeta_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Assuming you have a DataFrame df with your data\n",
    "# For example, let's assume 'medal' is the target column, and you want to drop it for the features\n",
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=9)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Neural Network\": MLPClassifier(),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Iterate through each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    # Create a pipeline with StandardScaler for classifiers that require it\n",
    "    if name not in [\"XGBoost\", \"Naive Bayes\", \"Neural Network\"]:\n",
    "        clf = make_pipeline(StandardScaler(), clf)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    beta = 2\n",
    "    f2_score = fbeta_score(y_test, y_pred, beta=beta)\n",
    "\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "        \"f2_score\": f2_score,\n",
    "    }\n",
    "\n",
    "for name, result in results.items():\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"F2-Score: {result['f2_score']:.4f}\")\n",
    "    print(f\"Classification Report:\\n{result['classification_report']}\")\n",
    "    print(f\"Confusion Matrix:\\n{result['confusion_matrix']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b80ddc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Logistic Regression\n",
      "Accuracy: 0.9627\n",
      "F2-Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       156\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.96       161\n",
      "   macro avg       0.48      0.50      0.49       161\n",
      "weighted avg       0.94      0.96      0.95       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[155   1]\n",
      " [  5   0]]\n",
      "\n",
      "Classifier: XGBoost\n",
      "Accuracy: 0.9752\n",
      "F2-Score: 0.4348\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       156\n",
      "           1       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.98       161\n",
      "   macro avg       0.82      0.70      0.74       161\n",
      "weighted avg       0.97      0.98      0.97       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[155   1]\n",
      " [  3   2]]\n",
      "\n",
      "Classifier: SVM\n",
      "Accuracy: 0.9689\n",
      "F2-Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       156\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.97       161\n",
      "   macro avg       0.48      0.50      0.49       161\n",
      "weighted avg       0.94      0.97      0.95       161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[156   0]\n",
      " [  5   0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Assuming you have a DataFrame df with your data\n",
    "# For example, let's assume 'medal' is the target column, and you want to drop it for the features\n",
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=9)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Iterate through each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    # Create a pipeline with StandardScaler for classifiers that require it\n",
    "    if name != \"XGBoost\":\n",
    "        clf = make_pipeline(StandardScaler(), clf)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    beta = 2\n",
    "    f2_score = fbeta_score(y_test, y_pred, beta=beta)\n",
    "\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "        \"f2_score\": f2_score,\n",
    "    }\n",
    "    \n",
    "for name, result in results.items():\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"F2-Score: {result['f2_score']:.4f}\")\n",
    "    print(f\"Classification Report:\\n{result['classification_report']}\")\n",
    "    print(f\"Confusion Matrix:\\n{result['confusion_matrix']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d1a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Combine_Data/men/pb_encoded.csv')\n",
    "\n",
    "name_counts = df['Name'].value_counts()\n",
    "\n",
    "# Extract names that appear 2 or more times\n",
    "names_with_multiple_occurrences = name_counts[name_counts >= 2].index\n",
    "\n",
    "# Filter the DataFrame based on condition\n",
    "df_filtered_names = df[df['Name'].isin(names_with_multiple_occurrences)]\n",
    "df=df_filtered_names.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619f82bf",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "475401cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200}\n",
      "Accuracy: 0.9905\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have a DataFrame df with your data\n",
    "# For example, let's assume 'medal' is the target column, and you want to drop it for the features\n",
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "# Define a parameter grid to search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, scoring='accuracy', cv=3)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Use the best parameters to initialize the final model\n",
    "final_model = XGBClassifier(**best_params)\n",
    "\n",
    "# Train the final model\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac43b82c",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa30a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "Rank: 0.2014\n",
      "D: 0.3239\n",
      "E: 0.0565\n",
      "ND: 0.0000\n",
      "Total: 0.0875\n",
      "year: 0.1975\n",
      "Name: 0.0543\n",
      "Nation: 0.0658\n",
      "round_final: 0.0131\n",
      "round_qual: 0.0000\n",
      "Accuracy: 0.99\n",
      "Precision: 0.75\n",
      "Recall: 1.00\n",
      "Confusion Matrix:\n",
      "[[101   1]\n",
      " [  0   3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnsAAAGDCAYAAABTHdZ+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAn1ElEQVR4nO3de5xeZX3v/c+3BOVoQIKCoqaei4qJRAtupShuW2s9W/EpHlC3VFu3W59NkafdrbGe8FStWGtjtei2IlpRUetZwAOiBhJAVNRKPAISiMhZEn7PH+sacxNnMvcwk7nvWfN5v17zmnWvax1+65o1mW+utdZ9p6qQJElSP/3OqAuQJEnSjmPYkyRJ6jHDniRJUo8Z9iRJknrMsCdJktRjhj1JkqQeM+xJGqkkhyf56Q7c/juS/O3A6xcmuSzJNUn2ad/vvqP2L0mjZtiTRizJHkk2JPmzgXl7JvlxkqcOzFuV5BNJNiX5ZZJvJ3l1kr1b+9FJtrTwck2SHyZ54Q6ufaigluQhSf6z1X1lkm8kec6OrG1CVb2gql7Z6tgZ+Afg0VW1R1Vd0b7/cD5qSbI8SQ38jK5Jct4cbXPJXNU5xD7PSPI/5mt/25PkpCSvGnUd0jgz7EkjVlXXAMcA/5hk3zb79cDaqvoPgCQPBc4Avgrct6r2Av4I2Aw8cGBzX2vhZQ/gqcDrk6yclwOZQpJDgS8CZwL3BPYBXgg8ZgTl3BHYBbhwthuaZbjaa+LnVFUPnH7xHSedBfm3IMlOo65BWggW5C+41DdV9Vngk8BbkxwOPA34y4FFXg/8W1W9tqoua+v8uKpeXlVnTLHNc4HvAL83MS/J45Nc2EbYzkgy2PZ7bd4v2zKPH2j74zaSeHWSnyU5NsnuwKeAOw2MUt1pklLeALynql5XVRurc05VPW2yupMcn+S/2r6+neRJA233THJmkquSbExySpufJG9O8ovWdn6S+7e2k5K8Ksm9gYvapn6Z5IutvZLcs03fNskb26jqZe0S8K6t7fAkP03ysiSXAv82Wf23VpL7JvlcG/m8KMnTBtoem2Rdkl8l+UmS1QOrfmngmK5JcmiS1UneN7D+LUb/2s/51Um+ClwH3H17+5+m7ol+Oa71/yVJntjOme+17f31wPKrk/xHklPaz/jcJA8caN/eeXhSkn9ON0p8LfA84CjguHbsH2/Lbe8cOjrJV9rPeVOSi5M8ZqD99kn+LcnPW/tHB9r+JMn6VttZSQ4aaHtZ+924uvXfEcP0nzQvqsovv/wagy9gb+ASYCPwnIH5uwNbgMOnWf9o4CsDrx8M/BK4d3t9b+Ba4L8DOwPHAT8AbtNe/wD46/b6kcDVwH3aupcADx+o80Ft+nDgp9upabdW+yO2s8wttgH8KXAnuv+MHtlq3r+1nQz8TWvbBXhYm/+HwDnAXkDoAu7EOicBr2rTy4EClgzsr4B7tum3AKcBtwf2BD4OvHagzs3A64DbArveip/xb+1/4Gf8E+A5wBLgQe08uN/Avh/Qjvsg4DLgids5ptXA+6baL90o8Y+B+7X9Ld3e/ic5jjOA/7FNv/wd3Xn0fOBy4P2tD+8H3ADcfaC2m+hGnncGjgUubtPTnYcnAVcB/23gHPjNz3fIc+jotv/nAzvRjTL/HEhr/yRwCt15vjPwB23+g4BfAL/f1ns2sKGdC/dp/Xengf6+x6j/TfHLr4kvR/akMVFVm+guL+4GnDrQtDfdH61LJ2YkeX0bXbg2yf8ZWPaQNv8a4BvA/wW+39qOBD5ZVZ+rqpuANwK7Ag8FDgH2AE6oql9X1ReBTwD/T1v3JuDAJLerqk3VjRoOY6L2S4Zcnqr6UFX9vKpurqpTWv0PGajjbnR/VG+oqq8MzN8TuC/dH+3vVNXQ+4RudJAuALy0qq6sqquB1wBPH1jsZuDlVXVjVV0/k+1vY2P7Of0yybHAnwAbqurfqmpz698P0wUiquqMqrqg9cn5dKH3D2axf4CTqurCqtpMd0vAlPsfwk3Aq9t59QFgGfCPVXV1VV1Id14fNLD8OVX1H235f6ALbYcw/XkI8LGq+mrrixsmK2aacwjgR1X1zqraArwH2B+4Y5L96W4veEE7z2+qqjPbOs8H/qWqvl5VW6rqPcCNreYtdKHvwCQ7V9WGqvqvIftO2uEMe9KYSPIMuhGBz9ONHk3YRBcy9p+YUVXHVXff3kfoRmImnF1Ve1V3z95+dKMqr2ltdwJ+NLCNm+lGI+7c2n7S5k34UWsDeArwx8CP2mXUQ4c8rN+qfTpJnjVwqeyXwP3pwgN0o5EBvtEu8T23HcsXgbcB/wRclmRNktsNu89mX7qgfc7Avj/d5k+4fKqA0Wq/MFsvaT98O/ta1n5Oe1XVG+kC7O8PBMBf0l2e3K9t9/eTnJ7k8iRXAS8Y6JNb6ycD09vd/xCuaMEJYCIEXzbQfj1diPutfbdz7qd05+B05+G2dU9qmnMIBv7jVFXXtck9gLsAV7b/eG3rbsD/3qaP7kL3H48fAC+hG7X8RZIPZPJbGqSRMOxJYyDJHYA3040e/DnwtCSHAVTVtcDXgSfPZJvV3dv3YeBxbdbP6f5gTewzdH+sftba7pJb3qh/19ZGVX2zqp4A3AH4KPDBid1MU8N1wNfowuK0ktwNeCfwImCfFmi/RRfwqKpLq+r5VXUnun56e9r9dlX11qo6mC7g3hv4q2H2OWAjXSi530AQW9qC828OaXsbqKr71dYHL748g33/BDhzYL97tW1MPE39frrLy3epqqXAO2h9MkVN19IF1wmThbbB9abb/1y7y8REO+cOoDsHt3seTlL3b72e7hyaxk+A2yfZa4q2V2/TR7tV1ckAVfX+qnoY3e9Yccv/sEkjZdiTxsPbgI9W1ent8uNxwDuT3La1Hwc8t914fgeAJAcAvzvVBpPsAzyJrU+efhB4bJIj0r0Fyf+muwx1Fl2YvJbuRved0z0k8jjgA0luk+SoJEvbZbdf0V22gm70Zp8kS7dzbMcBRyf5q1YTSR6Y5AOTLLs73R/Ky9tyz6EblZk4pj9txw3dqGEBW5I8uI1+7dyO44aBGofSRpPeCbx5oI/vnOQPZ7KdW+kTwL2TPLP1/87tmCYeoNmTbsTphiQPAf5sYN3L6UZPB98rcD1wWJK7tp/N/zfL/c+1g5M8Od0DIy+hOw/PZjvn4Xa2dRm3PPbtnkPb0373PkX3n4i9Ww2HteZ3Ai9o51mS7J7uwZk9k9wnySPb7+sNdP9pmNH5J+1Ihj1pxJI8EXgYAyNRVfWvdJe2/q69/grdzeqHAd8buMR4BnDiwOYOnbiMSPck7uXA/2zbuAh4Rlt+I90f0ce1e6N+DTye7n6ljcDbgWdV1Xfbdp8JbEjyK7pLiM9o2/wu3f1jP2yXtn7r0lVVndVqf2Rb7kpgDfCfkyz7beBNdKOBl9E9lPDVgUUeDHy9Hd9pwP+qqouB29H9Md5Ed9nvCrp7EmfqZXQPCJzdjvXzdDff71Dt/sBH090f+HO6y4wTD4IA/AXw90mupjsnPjiw7nXAq4Gvtp/BIVX1ObqHDM6ne3DlE7Pc/1z7GN09pJvozq0nt/vjpjsPJ/Muunvlfpnko0OcQ9N5Jt09iN+leyDjJQBVtZZu5P1tre4f0D3sAV0/ndBqvpRuBPyvkcbExNNHkiTtcOneNuaeVfWMUdciLRaO7EmSJPWYYU+SJKnHvIwrSZLUY47sSZIk9ZhhT5IkqceWTL/I4rRs2bJavnz5qMuQJEma1jnnnLOxqvadrM2wN4Xly5ezdu3aUZchSZI0rSQ/mqrNy7iSJEk9ZtiTJEnqMcOeJElSjxn2JEmSesywJ0mS1GOGPUmSpB4z7EmSJPWYYU+SJKnHDHuSJEk9ZtiTJEnqMcOeJElSjxn2JEmSesywJ0mS1GOGPUmSpB4z7EmSJPWYYU+SJKnHDHuSJEk9ZtiTJEnqMcOeJElSjxn2JEmSesywJ0mS1GOGPUmSpB4bm7CXZEOSZfOwn+VJvrWj9yNJkjQOZhT20hmbgChJkqTtmza4tZGw7yR5O3Au8K4k30pyQZIj2zKHJ/nEwDpvS3J0m96Q5BVJzm3r3LfN3yfJZ5OsS/IvQKap42+SXJTk80lOTnJsm39GklVtelmSDQN1f7nt99wkD70V/SNJkrSgDTtKdx/gvcCrgAOABwKPAt6QZP8h1t9YVQ8C/hk4ts17OfCVqloJnAbcdaqVkxwMPB1YCTwZePAQ+/wF8N/bfo8E3jrdCkmOSbI2ydrLL798iF1IkiSNt2HD3o+q6mzgYcDJVbWlqi4DzmS44HVq+34OsLxNHwa8D6CqPgls2s76Dwc+UlXXVdWv6MLhdHYG3pnkAuBDwIHTrVBVa6pqVVWt2nfffYfYhSRJ0nhbMuRy17bvU11q3cwtg+Mu27Tf2L5v2WafNeT+t7fs4L4H9/tS4DK6UcjfAW6Ywb4kSZJ6YaYPW3wJODLJTkn2pRud+wbwI+DAJLdNshQ4YshtHQWQ5DHA3tMs+6QkuybZE3jcQNsG4OA2/dSB+UuBS6rqZuCZwE5D1CRJktQrw47sTfgIcChwHt1I23FVdSlAkg8C5wPfB9YNsa1XACcnOZfucvCPp1qwqs5Ncgqwni5Yfnmg+Y3AB5M8E/jiwPy3Ax9O8qfA6WwdnZQkSVo0UjWTK6njIclq4JqqeuOO2seqVatq7dq1O2rzkiRJcybJOVW1arI23zNPkiSpx2Z6GXeHSrIP8IVJmo6oqismXlTV6nkrSpIkaQEbq7DXAt2KUdchSZLUF17GlSRJ6jHDniRJUo8Z9iRJknrMsCdJktRjhj1JkqQeM+xJkiT1mGFPkiSpxwx7kiRJPWbYkyRJ6rGx+gSNcXLpdZs5Yd3GOd/u8SuXzfk2JUmSpuLIniRJUo8Z9iRJknrMsCdJktRjhj1JkqQeM+xJkiT1mGFPkiSpxwx7kiRJPWbYkyRJ6rGxCXtJNiSZ8h2Hk7w4yXeS/HuSxyc5fhb7uubWritJkrSQzOgTNJIESFXdvIPq2Z6/AB5TVRe316eNoAZJkqQFZdqRvSTL24ja24FzgXcl+VaSC5Ic2ZY5PMknBtZ5W5Kj2/SGJK9Icm5b575t/j5JPptkXZJ/AbKdGt4B3B04LclLkxyd5G2t7aQkb01yVpIfJnlqm79Hki8M7PcJt7aTJEmSFqphL+PeB3gv8CrgAOCBwKOANyTZf4j1N1bVg4B/Bo5t814OfKWqVtKN0t11qpWr6gXAz4FHVNWbJ1lkf+BhwJ8AJ7R5NwBPavt9BPCmNjI5pSTHJFmbZO21m64Y4rAkSZLG27Bh70dVdTZdoDq5qrZU1WXAmcCDh1j/1Pb9HGB5mz4MeB9AVX0S2DRs0ZP4aFXdXFXfBu7Y5gV4TZLzgc8Ddx5om1RVramqVVW1ave995lFOZIkSeNh2Hv2rm3fpxoZ28wtg+Mu27Tf2L5v2WafNeT+p3PjwPREjUcB+wIHV9VNSTZMUpckSVKvzfRp3C8BRybZKcm+dKNz3wB+BByY5LZJlgJHDLmtowCSPAbYe4a1TGcp8IsW9B4B3G2Oty9JkjT2ZvQ0LvAR4FDgPLpRueOq6lKAJB8Ezge+D6wbYluvAE5Oci7d5eAfz7CW6fw78PEka4H1wHfnePuSJEljL1VzdSW1Xw44cEW96N8/P+fbPX7llG8lKEmSdKskOaeqVk3WNjZvqixJkqS5N9PLuDtUkn2AL0zSdERV+V4okiRJMzRWYa8FuhWjrkOSJKkvvIwrSZLUY4Y9SZKkHjPsSZIk9dhY3bM3TvbbbYlvkyJJkhY8R/YkSZJ6zLAnSZLUY4Y9SZKkHjPsSZIk9ZhhT5Ikqcd8GncKl163mRPWbRx1GRqST05LkjQ5R/YkSZJ6zLAnSZLUY4Y9SZKkHjPsSZIk9ZhhT5IkqccMe5IkST1m2JMkSeoxw54kSVKPjTTsJakkbxp4fWyS1dOsc3iShw68fkGSZ+3AMiVJkhasUY/s3Qg8OclMPv7gcOA3Ya+q3lFV753rwiRJkvpg1GFvM7AGeOm2DUkel+TrSdYl+XySOyZZDrwAeGmS9UkenmR1kmPbOiuSnJ3k/CQfSbJ3m39Gktcl+UaS7yV5+DweoyRJ0siMOuwB/BNwVJKl28z/CnBIVa0EPgAcV1UbgHcAb66qFVX15W3WeS/wsqo6CLgAePlA25Kqegjwkm3m/0aSY5KsTbL22k1XzPa4JEmSRm7JqAuoql8leS/wYuD6gaYDgFOS7A/cBrh4e9tpYXGvqjqzzXoP8KGBRU5t388Blk9Ryxq6kUYOOHBFzexIJEmSxs84jOwBvAV4HrD7wLwTgbdV1QOAPwd2meU+bmzftzAGIVeSJGk+jEXYq6orgQ/SBb4JS4GftelnD8y/Gthzkm1cBWwauB/vmcCZ2y4nSZK0mIxF2GveBAw+lbsa+FCSLwMbB+Z/HHjSxAMa22zj2cAbkpwPrAD+fseVK0mSNP5GejmzqvYYmL4M2G3g9ceAj02yzveAgwZmfXmgbT1wyCTrHD4wvZEp7tmTJEnqm3Ea2ZMkSdIcM+xJkiT1mGFPkiSpxwx7kiRJPWbYkyRJ6jHDniRJUo/5SRJT2G+3JRy/ctn0C0qSJI0xR/YkSZJ6zLAnSZLUY4Y9SZKkHjPsSZIk9ZhhT5Ikqcd8GncKl163mRPWbRx1Gb3m086SJO14juxJkiT1mGFPkiSpxwx7kiRJPWbYkyRJ6jHDniRJUo8Z9iRJknrMsCdJktRjhj1JkqQeG6uwl6SSvGng9bFJVo+wJEmSpAVtrMIecCPw5CR+tIIkSdIcGLewtxlYA7x024Ykj0vy9STrknw+yR3b/NVJ3pPks0k2JHlyktcnuSDJp5Ps3JY7OMmZSc5J8pkk+8/voUmSJM2/cQt7AP8EHJVk6TbzvwIcUlUrgQ8Axw203QN4LPAE4H3A6VX1AOB64LEt8J0IPLWqDgbeDbx62x0nOSbJ2iRrr910xVwflyRJ0rxbMuoCtlVVv0ryXuDFdGFtwgHAKW1E7jbAxQNtn6qqm5JcAOwEfLrNvwBYDtwHuD/wuSS0ZS6ZZN9r6EYWOeDAFTWHhyVJkjQS4ziyB/AW4HnA7gPzTgTe1kbs/hzYZaDtRoCquhm4qaomgtrNdIE2wIVVtaJ9PaCqHr2Dj0GSJGnkxjLsVdWVwAfpAt+EpcDP2vSzZ7jJi4B9kxwKkGTnJPebdaGSJEljbizDXvMmYPCp3NXAh5J8Gdg4kw1V1a+BpwKvS3IesB546NyUKUmSNL7G6p69qtpjYPoyYLeB1x8DPjbJOqu3s43VA9PrgcPmsl5JkqRxN84je5IkSZolw54kSVKPGfYkSZJ6zLAnSZLUY4Y9SZKkHjPsSZIk9dhYvfXKONlvtyUcv3LZ9AtKkiSNMUf2JEmSesywJ0mS1GOGPUmSpB4z7EmSJPWYYU+SJKnHfBp3Cpdet5kT1m0cdRmSNHK+M4G0sDmyJ0mS1GOGPUmSpB4z7EmSJPWYYU+SJKnHDHuSJEk9ZtiTJEnqMcOeJElSjxn2JEmSesywJ0mS1GOLNuwl2WnUNUiSJO1oCyLsJXllkv818PrVSV6c5K+SfDPJ+UleMdD+0STnJLkwyTED869J8vdJvg4cOs+HIUmSNO8WRNgD3gU8GyDJ7wBPBy4D7gU8BFgBHJzksLb8c6vqYGAV8OIk+7T5uwPfqqrfr6qvzGP9kiRJI7Fk1AUMo6o2JLkiyUrgjsA64MHAo9s0wB504e9LdAHvSW3+Xdr8K4AtwIen2k8bBTwGYK/9DtgBRyJJkjS/FkTYa/4VOBrYD3g3cATw2qr6l8GFkhwOPAo4tKquS3IGsEtrvqGqtky1g6paA6wBOODAFTW35UuSJM2/hXIZF+AjwB/Rjeh9pn09N8keAEnunOQOwFJgUwt69wUOGVXBkiRJo7ZgRvaq6tdJTgd+2UbnPpvk94CvJQG4BngG8GngBUnOBy4Czh5VzZIkSaO2YMJeezDjEOBPJ+ZV1T8C/zjJ4o+ZbBtVtceOqU6SJGk8LYjLuEkOBH4AfKGqvj/qeiRJkhaKBTGyV1XfBu4+6jokSZIWmgUxsidJkqRbx7AnSZLUY4Y9SZKkHjPsSZIk9ZhhT5IkqccWxNO4o7Dfbks4fuWyUZchSZI0K47sSZIk9ZhhT5IkqccMe5IkST1m2JMkSeoxw54kSVKP+TTuFC69bjMnrNs46jK0QPkktyRpXDiyJ0mS1GOGPUmSpB4z7EmSJPWYYU+SJKnHDHuSJEk9ZtiTJEnqMcOeJElSj4192EuyT5L17evSJD8beH2bbZZ9SZLdhtjmGUlW7biqJUmSxsPYv6lyVV0BrABIshq4pqreOMXiLwHeB1w3H7VJkiSNu7Ef2ZtMkiOSrEtyQZJ3J7ltkhcDdwJOT3J6W+6fk6xNcmGSV4y2akmSpPm3EMPeLsBJwJFV9QC60ckXVtVbgZ8Dj6iqR7Rl/6aqVgEHAX+Q5KBRFCxJkjQqCzHs7QRcXFXfa6/fAxw2xbJPS3IusA64H3Dg9jac5Jg2Erj22k1XzFnBkiRJo7IQw961wyyU5HeBY4Ejquog4JN0o4JTqqo1VbWqqlbtvvc+s69UkiRpxBZi2NsFWJ7knu31M4Ez2/TVwJ5t+nZ0wfCqJHcEHjOvVUqSJI2BsX8adxI3AM8BPpRkCfBN4B2tbQ3wqSSXVNUjkqwDLgR+CHx1JNVKkiSN0IIKe1W1euDlyknaTwROHHh99BTbOXyOS5MkSRpLC/EyriRJkoZk2JMkSeoxw54kSVKPGfYkSZJ6zLAnSZLUY4Y9SZKkHjPsSZIk9diCep+9+bTfbks4fuWyUZchSZI0K47sSZIk9ZhhT5IkqccMe5IkST1m2JMkSeoxw54kSVKPGfYkSZJ6zLAnSZLUY4Y9SZKkHjPsSZIk9ZhhT5IkqccMe5IkST1m2JMkSeoxw54kSVKPGfYkSZJ6rBdhL0kledPA62OTrG7Tq5P8LMn6JN9PcmqSA0dWrCRJ0jzqRdgDbgSenGTZFO1vrqoVVXUv4BTgi0n2nb/yJEmSRqMvYW8zsAZ46XQLVtUpwGeBP9vRRUmSJI1aX8IewD8BRyVZOsSy5wL33XZmkmOSrE2y9vLLL5/zAiVJkuZbb8JeVf0KeC/w4iEWzxTbWFNVq6pq1b77epVXkiQtfL0Je81bgOcBu0+z3ErgOzu8GkmSpBHrVdirqiuBD9IFvkkleQrwaODk+apLkiRpVHoV9po3Ads+lfvSibdeAZ4BPLKqvClPkiT13pJRFzAXqmqPgenLgN0GXq8GVs9/VZIkSaPXx5E9SZIkNYY9SZKkHjPsSZIk9ZhhT5IkqccMe5IkST1m2JMkSeoxw54kSVKPGfYkSZJ6zLAnSZLUY4Y9SZKkHjPsSZIk9ZhhT5IkqceWjLqAcXXpdZs5Yd3GUZexqBy/ctmoS5AkqXcc2ZMkSeoxw54kSVKPGfYkSZJ6zLAnSZLUY4Y9SZKkHjPsSZIk9ZhhT5IkqccMe5IkST22aN5UOckW4IKBWR+oqhNGVY8kSdJ8WDRhD7i+qlaMughJkqT55GVcSZKkHltMYW/XJOsHvo7cdoEkxyRZm2TttZuuGEWNkiRJc8rLuAOqag2wBuCAA1fUfBQlSZK0Iy2mkT1JkqRFx7AnSZLUY4vpMu6uSdYPvP50VR0/qmIkSZLmw6IJe1W106hrkCRJmm9expUkSeoxw54kSVKPGfYkSZJ6zLAnSZLUY4Y9SZKkHjPsSZIk9diieeuVmdpvtyUcv3LZqMuQJEmaFUf2JEmSesywJ0mS1GOGPUmSpB4z7EmSJPWYYU+SJKnHDHuSJEk95luvTOHS6zZzwrqNoy5DkiQtYOPwNm6O7EmSJPWYYU+SJKnHDHuSJEk9ZtiTJEnqMcOeJElSjxn2JEmSesywJ0mS1GO9f5+9JFuAC4Cdgc3Ae4C3VNXNIy1MkiRpHvQ+7AHXV9UKgCR3AN4PLAVePsqiJEmS5sOiuoxbVb8AjgFelCSjrkeSJGlHW1RhD6Cqfkh33HcYdS2SJEk72qILe82ko3pJjkmyNsnaazddMd81SZIkzblFF/aS3B3YAvxi27aqWlNVq6pq1e577zP/xUmSJM2xRRX2kuwLvAN4W1XVqOuRJEna0RbD07i7JlnP1rde+b/AP4y0IkmSpHnS+7BXVTuNugZJkqRRWVSXcSVJkhYbw54kSVKPGfYkSZJ6zLAnSZLUY4Y9SZKkHjPsSZIk9ZhhT5Ikqcd6/z57t9Z+uy3h+JXLRl2GJEnSrDiyJ0mS1GOGPUmSpB4z7EmSJPWYYU+SJKnHDHuSJEk95tO4U7j0us2csG7jqMuQpLHmuxZI48+RPUmSpB4z7EmSJPWYYU+SJKnHDHuSJEk9ZtiTJEnqMcOeJElSjxn2JEmSemysw16SLUnWJ/lWko8n2WsW27pmDkuTJElaEMY67AHXV9WKqro/cCXwl6MuSJIkaSEZ97A36GvAnQGSPCTJWUnWte/3afOPTnJqkk8n+X6S12+7kSTLknwtyWPnuX5JkqR5tyA+Li3JTsARwLvarO8Ch1XV5iSPAl4DPKW1rQBWAjcCFyU5sap+0rZzR+A04P9U1efm8RAkSZJGYtzD3q5J1gPLgXOAiYC2FHhPknsBBew8sM4XquoqgCTfBu4G/KQt8wXgL6vqzMl2luQY4BiAvfY7YK6PRZIkad6N+2Xc66tqBV1guw1b79l7JXB6u5fvccAuA+vcODC9ha2BdjNdYPzDqXZWVWuqalVVrdp9733m5ggkSZJGaNzDHgBtpO7FwLFJdqYb2ftZaz562M0AzwXum+T4OS9SkiRpDC2IsAdQVeuA84CnA68HXpvkq8BOM9jGlrb+I5L8xQ4pVJIkaYyM9T17VbXHNq8fN/Dy3gPTf9vaTwJOGlj+T7bdVlX9mu1cypUkSeqTBTOyJ0mSpJkz7EmSJPWYYU+SJKnHDHuSJEk9ZtiTJEnqMcOeJElSjxn2JEmSemys32dvlPbbbQnHr1w26jIkSZJmxZE9SZKkHjPsSZIk9ZhhT5IkqccMe5IkST1m2JMkSeoxw54kSVKPGfYkSZJ6zLAnSZLUY4Y9SZKkHjPsSZIk9ZhhT5IkqccMe5IkST1m2JMkSeoxw54kSVKPpapGXcNYSnI1cNGo6+iBZcDGURfRA/bj3LAf54b9ODfsx7lhP3buVlX7TtawZL4rWUAuqqpVoy5ioUuy1n6cPftxbtiPc8N+nBv249ywH6fnZVxJkqQeM+xJkiT1mGFvamtGXUBP2I9zw36cG/bj3LAf54b9ODfsx2n4gIYkSVKPObInSZLUY4sy7CX5oyQXJflBkuMnaU+St7b285M8aNh1F5NZ9uOGJBckWZ9k7fxWPl6G6Mf7JvlakhuTHDuTdReTWfaj52MzRD8e1X6fz09yVpIHDrvuYjLLfvR8bIboxye0PlyfZG2Shw277qJSVYvqC9gJ+C/g7sBtgPOAA7dZ5o+BTwEBDgG+Puy6i+VrNv3Y2jYAy0Z9HKP+GrIf7wA8GHg1cOxM1l0sX7Ppx9bm+Th8Pz4U2LtNP8Z/H+e2H9trz8fh+3EPtt6SdhDw3WHXXUxfi3Fk7yHAD6rqh1X1a+ADwBO2WeYJwHurczawV5L9h1x3sZhNP2qrafuxqn5RVd8EbprpuovIbPpRWw3Tj2dV1ab28mzggGHXXURm04/aaph+vKZaugN2B2rYdReTxRj27gz8ZOD1T9u8YZYZZt3FYjb9CN0v5GeTnJPkmB1W5fibzTnl+bjVbPvC87Ez0358Ht3o/a1Zt89m04/g+ThhqH5M8qQk3wU+CTx3JusuFovxEzQyybxtH0meaplh1l0sZtOPAP+tqn6e5A7A55J8t6q+NKcVLgyzOac8H7eabV94PnaG7sckj6ALKRP3SHk+bjWbfgTPxwlD9WNVfQT4SJLDgFcCjxp23cViMY7s/RS4y8DrA4CfD7nMMOsuFrPpR6pq4vsvgI/QDbkvRrM5pzwft5pVX3g+/sZQ/ZjkIOBfgSdU1RUzWXeRmE0/ej5uNaNzqgXieyRZNtN1+24xhr1vAvdK8rtJbgM8HThtm2VOA57VniY9BLiqqi4Zct3F4lb3Y5Ldk+wJkGR34NHAt+az+DEym3PK83GrW90Xno+3MG0/JrkrcCrwzKr63kzWXURudT96Pt7CMP14zyRp0w+iexjjimHWXUwW3WXcqtqc5EXAZ+ie1nl3VV2Y5AWt/R3Af9I9SfoD4DrgOdtbdwSHMXKz6UfgjnRD7tCdg++vqk/P8yGMhWH6Mcl+wFrgdsDNSV5C91TZrzwfO7PpR2AZno/A0L/XfwfsA7y99dnmqlrlv49bzaYf8d/H3xiyH59CN6hwE3A9cGR7YMPzcYCfoCFJktRji/EyriRJ0qJh2JMkSeoxw54kSVKPGfYkSZJ6zLAnSZLUY4Y9SQtKki1J1g98Lb8V23hikgN3QHkkWZ5kXt8XLcmKJH88n/uUtHAsuvfZk7TgXV9VK2a5jScCnwC+PewKSZZU1eZZ7nfOJVkCrABW0b23pSTdgiN7kha8JAcnObN9cPxnkuzf5j8/yTeTnJfkw0l2S/JQ4PHAG9rI4D2SnJFkVVtnWZINbfroJB9K8nG6D6bfPcm72zbXJXnCNHUdneSjST6e5OIkL0ry/7Z1z05y+7bcGUnekuSsJN9K8pA2//Zt/fPb8ge1+auTrEnyWeC9wN8DR7bjOTLJQ9q21rXv9xmo59Qkn07y/SSvH6j1j5Kc2/rqC23ejI5X0nhyZE/SQrNrkvVt+mLgacCJdJ8venmSI4FXA88FTq2qdwIkeRXwvKo6MclpwCeq6j9a2/b2dyhwUFVdmeQ1wBer6rlJ9gK+keTzVXXtdta/P7AS2IXu02ReVlUrk7wZeBbwlrbc7lX10HQf5v7utt4rgHVV9cQkj6QLdiva8gcDD6uq65McDayqqhe147kdcFj7BIJHAa+h+6QB2vorgRuBi5KcCNwAvLOtc/FECAX+5lYcr6QxY9iTtNDc4jJukvvTBaPPtdC2E3BJa75/C3l7AXvQfXTSTH2uqq5s048GHp/k2PZ6F+CuwHe2s/7pVXU1cHWSq4CPt/kXAAcNLHcydB/mnuR2LVw9jBbSquqLSfZJsrQtf1pVXT/FPpcC70lyL6CAnQfavlBVVwEk+TZwN2Bv4EtVdXHb12yOV9KYMexJWugCXFhVh07SdhLwxKo6r41+HT7FNjaz9baWXbZpGxzFCvCUqrpoBvXdODB988Drm7nlv8HbfnZltf1ta2K57Y2uvZIuZD6pPcByxhT1bGk1ZJL9w607Xkljxnv2JC10FwH7JjkUIMnOSe7X2vYELkmyM3DUwDpXt7YJG+guiwI8dTv7+gzwP9OGEJOsnH35v3Fk2+bDgKva6NuXaHUnORzYWFW/mmTdbY9nKfCzNn30EPv+GvAHSX637WviMu6OPF5J88SwJ2lBq6pf0wW01yU5D1gPPLQ1/y3wdeBzwHcHVvsA8FftoYN7AG8EXpjkLGDZdnb3SrpLouene3uVV87hoWxq+38H8Lw2bzWwKsn5wAnAs6dY93TgwIkHNIDXA69N8lW6y9rbVVWXA8cAp7Y+PKU17cjjlTRPUjXZyL0kab4kOQM4tqrWjroWSf3jyJ4kSVKPObInSZLUY47sSZIk9ZhhT5IkqccMe5IkST1m2JMkSeoxw54kSVKPGfYkSZJ67P8HaApK+hWgrpoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have X_train, X_test, y_train, y_test already defined\n",
    "\n",
    "# MaxAbsScaler to scale features\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Set XGBoost best parameters\n",
    "params = {\n",
    "    'learning_rate': 0.2,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "    'n_estimators': 200,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss', \n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Create and fit XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(**params)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Extract feature importances from the trained XGBoost model\n",
    "feature_importances = xgb_model.feature_importances_\n",
    "\n",
    "# Print feature importances\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in zip(X.columns, feature_importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(X.columns, feature_importances, color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('XGBoost Classifier - Feature Importances')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b589dd6c",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e2756ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "Precision: 0.75\n",
      "Recall: 1.00\n",
      "Confusion Matrix:\n",
      "[[101   1]\n",
      " [  0   3]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import pandas as pd\n",
    "\n",
    "X = df.drop(columns=['medal'])\n",
    "y = df['medal']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# MaxAbsScaler to scale  features\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Set XGBoost best parameters\n",
    "params = {\n",
    "    'learning_rate': 0.2,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "    'n_estimators': 200,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss', \n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Create  fit XGBoost \n",
    "xgb_model = xgb.XGBClassifier(**params)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# prediction\n",
    "y_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06132db",
   "metadata": {},
   "source": [
    "# Model Trained earlier, now using 2023/2022 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e10d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp = pd.read_csv('../../Data/cleandata22-23/encoded_m_olympics_pb.csv')\n",
    "olymp.rename(columns={'D Score': 'D', 'E Score': 'E',\n",
    "                     'Pen.': 'ND', 'nation': 'Nation'}, inplace=True)\n",
    "olymp=olymp.drop(columns=['round_TeamFinal', 'round_AAfinal', 'round_TeamQual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c49ea5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=final_model.predict(olymp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "793ae23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds  = pd.Series(y_pred)\n",
    "olymp['ypred']=ypreds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b623e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = olymp[olymp['ypred'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdebf1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([390, 286, 747, 746,  20, 139, 719, 552, 384, 716, 333,  21])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaeb565",
   "metadata": {},
   "source": [
    "# pbnames used to match encoded names with actual names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1779cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_encoded_values = [390, 286, 747, 746,  20, 139, 719, 552, 384, 716, 333,  21]\n",
    "\n",
    "# Filter the DataFrame to get the corresponding \"Name\" values\n",
    "result = pbnames.loc[pbnames['Name_encoded'].isin(name_encoded_values), 'Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e67c6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kazuma kaya', 'illia kovtun', 'yul moldauer',\n",
       "       'yul kyung tae moldauer', 'ahmet onder', 'curran phillips',\n",
       "       'wichol ri', 'noe seifert', 'kakeru tanigawa', 'wataru tanigawa',\n",
       "       'jingyuan zou', 'ahmet önder'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dc845f",
   "metadata": {},
   "source": [
    "# pbolymp used to get country info from name list above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffc31876",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbolymp[\"Name\"]=pbolymp[\"Name\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef945b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_filter =['kazuma kaya', 'illia kovtun', 'yul moldauer',\n",
    "       'yul kyung tae moldauer', 'ahmet onder', 'curran phillips',\n",
    "       'wichol ri', 'noe seifert', 'kakeru tanigawa', 'wataru tanigawa',\n",
    "       'jingyuan zou', 'ahmet önder']\n",
    "# Filter the DataFrame to get rows with the specified \"Name\" values\n",
    "result = pbolymp[pbolymp['Name'].isin(names_to_filter)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39bd774f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "UKR    151\n",
       "USA     96\n",
       "JPN     84\n",
       "TUR     62\n",
       "SUI     56\n",
       "CHN     16\n",
       "PRK     11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afd7eaa",
   "metadata": {},
   "source": [
    "# Find names from USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea506b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = result[result['Country']=='USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "716b31d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['yul moldauer', 'yul kyung tae moldauer', 'curran phillips'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa['Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922c2f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
