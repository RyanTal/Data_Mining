{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b311890",
   "metadata": {},
   "source": [
    "# USA Gymnast with best chances to medal in fx are:\n",
    "\n",
    "- Simone Biles\n",
    "\n",
    "## Scaling - no improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3536b78f",
   "metadata": {},
   "source": [
    "KNeighborsClassifier keeps returning eveylynn lowe, who should be there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ce80f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from mlxtend.preprocessing import minmax_scaling\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f241c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../../Combine_Data/women/fx_encoded.csv')\n",
    "olymp = pd.read_csv('../../Data/cleandata22-23/encoded_w_olympics_fx.csv')\n",
    "fxnames = pd.read_csv('../../Data/cleandata22-23/encoded_w_olympics_fxnames.csv')\n",
    "fxolymp = pd.read_csv('../../Data/cleandata22-23/women22_23.csv')\n",
    "\n",
    "df = pd.read_csv('../../Combine_Data/women/mult_fx_encoded.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a6eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['tot_final',\n",
    "       'tot_fin_d', 'tot_fin_ddiv', 'tot_fin_ddiv_rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc4233ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rank', 'D Score', 'E Score', 'Pen.', 'Total', 'year', 'medal', 'Name',\n",
       "       'nation', 'round_0', 'round_final', 'round_qual'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdb95982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>D Score</th>\n",
       "      <th>E Score</th>\n",
       "      <th>Pen.</th>\n",
       "      <th>Total</th>\n",
       "      <th>year</th>\n",
       "      <th>medal</th>\n",
       "      <th>Name</th>\n",
       "      <th>nation</th>\n",
       "      <th>round_0</th>\n",
       "      <th>round_final</th>\n",
       "      <th>round_qual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>8.266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.466</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>43</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>7.833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.433</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>8.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.300</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>7.933</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>13.233</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.200</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>68.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.266</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>70.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.233</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>72.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.100</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>74.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.333</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>11.033</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>41</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>75.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.933</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank  D Score  E Score  Pen.   Total  year  medal  Name  nation  round_0  \\\n",
       "0     1.0      6.2    8.266   0.0  14.466  2019      1    66      43    False   \n",
       "1     2.0      5.6    7.833   0.0  13.433  2019      0    78      22    False   \n",
       "2     3.0      5.2    8.100   0.0  13.300  2019      1   126      22    False   \n",
       "3     4.0      5.4    7.933  -0.1  13.233  2019      0    94      31    False   \n",
       "4     5.0      5.0    8.200   0.0  13.200  2019      0    93      13    False   \n",
       "..    ...      ...      ...   ...     ...   ...    ...   ...     ...      ...   \n",
       "284  68.0      4.9    6.366   0.0  11.266  2015      0    37      41    False   \n",
       "285  70.0      4.4    6.833   0.0  11.233  2015      0   119      29    False   \n",
       "286  72.0      3.6    7.500   0.0  11.100  2015      0     8      25    False   \n",
       "287  74.0      5.1    6.333  -0.4  11.033  2015      0    45      41    False   \n",
       "288  75.0      4.0    6.933   0.0  10.933  2015      0    10       5    False   \n",
       "\n",
       "     round_final  round_qual  \n",
       "0           True       False  \n",
       "1           True       False  \n",
       "2           True       False  \n",
       "3           True       False  \n",
       "4           True       False  \n",
       "..           ...         ...  \n",
       "284        False        True  \n",
       "285        False        True  \n",
       "286        False        True  \n",
       "287        False        True  \n",
       "288        False        True  \n",
       "\n",
       "[289 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea72e9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 289 entries, 0 to 288\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Rank         289 non-null    float64\n",
      " 1   D Score      289 non-null    float64\n",
      " 2   E Score      289 non-null    float64\n",
      " 3   Pen.         289 non-null    float64\n",
      " 4   Total        289 non-null    float64\n",
      " 5   year         289 non-null    int64  \n",
      " 6   medal        289 non-null    int64  \n",
      " 7   Name         289 non-null    int64  \n",
      " 8   nation       289 non-null    int64  \n",
      " 9   round_0      289 non-null    bool   \n",
      " 10  round_final  289 non-null    bool   \n",
      " 11  round_qual   289 non-null    bool   \n",
      "dtypes: bool(3), float64(5), int64(4)\n",
      "memory usage: 21.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "044a98a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>D Score</th>\n",
       "      <th>E Score</th>\n",
       "      <th>Pen.</th>\n",
       "      <th>Total</th>\n",
       "      <th>year</th>\n",
       "      <th>medal</th>\n",
       "      <th>Name</th>\n",
       "      <th>nation</th>\n",
       "      <th>round_0</th>\n",
       "      <th>round_final</th>\n",
       "      <th>round_qual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>8.266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.466</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>43</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>7.833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.433</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>8.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.300</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>7.933</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>13.233</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.200</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank  D Score  E Score  Pen.   Total  year  medal  Name  nation  round_0  \\\n",
       "0   1.0      6.2    8.266   0.0  14.466  2019      1    66      43    False   \n",
       "1   2.0      5.6    7.833   0.0  13.433  2019      0    78      22    False   \n",
       "2   3.0      5.2    8.100   0.0  13.300  2019      1   126      22    False   \n",
       "3   4.0      5.4    7.933  -0.1  13.233  2019      0    94      31    False   \n",
       "4   5.0      5.0    8.200   0.0  13.200  2019      0    93      13    False   \n",
       "\n",
       "   round_final  round_qual  \n",
       "0         True       False  \n",
       "1         True       False  \n",
       "2         True       False  \n",
       "3         True       False  \n",
       "4         True       False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f2fc930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# june 6 2017 till 2020 olympics = 1529\n",
    "# 2018 = 1164\n",
    "# 2019 = 799\n",
    "# 2020 = 433\n",
    "\n",
    "# june 6 2013 till  2016 olympics = 1177\n",
    "# 2014 = 812\n",
    "# 2015 = 447\n",
    "# 2016 = 90\n",
    "\n",
    "\n",
    "# dats till 2024 olympics = \n",
    "# 2022 = 796\n",
    "# 2023 = 431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbbbdaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c0009f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Random Forest\n",
      "Accuracy: 0.9655\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        56\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.97        58\n",
      "   macro avg       0.74      0.74      0.74        58\n",
      "weighted avg       0.97      0.97      0.97        58\n",
      "\n",
      "Confusion Matrix:\n",
      "[[55  1]\n",
      " [ 1  1]]\n",
      "\n",
      "Classifier: AdaBoost\n",
      "Accuracy: 0.9483\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        56\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.95        58\n",
      "   macro avg       0.66      0.73      0.69        58\n",
      "weighted avg       0.96      0.95      0.95        58\n",
      "\n",
      "Confusion Matrix:\n",
      "[[54  2]\n",
      " [ 1  1]]\n",
      "\n",
      "Classifier: SVM\n",
      "Accuracy: 0.9655\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        56\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.97        58\n",
      "   macro avg       0.48      0.50      0.49        58\n",
      "weighted avg       0.93      0.97      0.95        58\n",
      "\n",
      "Confusion Matrix:\n",
      "[[56  0]\n",
      " [ 2  0]]\n",
      "\n",
      "Classifier: K-Nearest Neighbors\n",
      "Accuracy: 0.9828\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        56\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.98        58\n",
      "   macro avg       0.99      0.75      0.83        58\n",
      "weighted avg       0.98      0.98      0.98        58\n",
      "\n",
      "Confusion Matrix:\n",
      "[[56  0]\n",
      " [ 1  1]]\n",
      "\n",
      "Classifier: Decision Tree\n",
      "Accuracy: 0.9310\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        56\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.93        58\n",
      "   macro avg       0.62      0.72      0.65        58\n",
      "weighted avg       0.96      0.93      0.94        58\n",
      "\n",
      "Confusion Matrix:\n",
      "[[53  3]\n",
      " [ 1  1]]\n",
      "\n",
      "Classifier: Naive Bayes\n",
      "Accuracy: 0.6379\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77        56\n",
      "           1       0.09      1.00      0.16         2\n",
      "\n",
      "    accuracy                           0.64        58\n",
      "   macro avg       0.54      0.81      0.46        58\n",
      "weighted avg       0.97      0.64      0.75        58\n",
      "\n",
      "Confusion Matrix:\n",
      "[[35 21]\n",
      " [ 0  2]]\n",
      "\n",
      "Classifier: Neural Network\n",
      "Accuracy: 0.9483\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        56\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95        58\n",
      "   macro avg       0.48      0.49      0.49        58\n",
      "weighted avg       0.93      0.95      0.94        58\n",
      "\n",
      "Confusion Matrix:\n",
      "[[55  1]\n",
      " [ 2  0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryantalbot/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Neural Network\": MLPClassifier(),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Iterate through each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    # Create a pipeline with StandardScaler for classifiers that require it\n",
    "    if name in [\"SVM\", \"K-Nearest Neighbors\", \"Neural Network\"]:\n",
    "        clf = make_pipeline(StandardScaler(), clf)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for name, result in results.items():\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"Classification Report:\\n{result['classification_report']}\")\n",
    "    print(f\"Confusion Matrix:\\n{result['confusion_matrix']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49120804",
   "metadata": {},
   "source": [
    "using days instead of year\n",
    "\n",
    "Classifier: Random Forest\n",
    "Accuracy: 0.9659\n",
    "\n",
    "Classifier: AdaBoost\n",
    "Accuracy: 0.9659\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e1b05b",
   "metadata": {},
   "source": [
    "Classifier: Random Forest\n",
    "Accuracy: 0.9659\n",
    "\n",
    "Classifier: SVM\n",
    "Accuracy: 0.9545\n",
    "\n",
    "Classifier: K-Nearest Neighbors\n",
    "Accuracy: 0.9659\n",
    "\n",
    "Classifier: Neural Network\n",
    "Accuracy: 0.9659\n",
    "\n",
    "Classifier: AdaBoost\n",
    "Accuracy: 0.9659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c940853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier\n",
      "Accuracy: 0.9545\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        42\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.95        44\n",
      "   macro avg       0.74      0.74      0.74        44\n",
      "weighted avg       0.95      0.95      0.95        44\n",
      "\n",
      "Confusion Matrix:\n",
      "[[41  1]\n",
      " [ 1  1]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming you already have your DataFrame 'df' and the target variable is 'medal'\n",
    "y = df['medal']\n",
    "X = df.drop(columns=['medal'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Initialize the AdaBoost classifier\n",
    "clf = AdaBoostClassifier(n_estimators=1000, learning_rate=.00047,\n",
    "                         random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"AdaBoost Classifier\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "906e5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "# from sklearn.gaussian_process.kernels import RBF\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# # Assuming 'medal' is the target variable\n",
    "# X = df.drop('medal', axis=1)\n",
    "# y = df['medal']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize Gaussian Process Classifier with Radial Basis Function (RBF) kernel\n",
    "# kernel = 1.0 * RBF(length_scale=1.0)\n",
    "# gpc = GaussianProcessClassifier(kernel=kernel, random_state=42)\n",
    "\n",
    "# # Fit the model to the training data\n",
    "# gpc.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred_gpc = gpc.predict(X_test)\n",
    "\n",
    "# # Evaluate the model's performance\n",
    "# accuracy_gpc = accuracy_score(y_test, y_pred_gpc)\n",
    "# report_gpc = classification_report(y_test, y_pred_gpc)\n",
    "# conf_matrix_gpc = confusion_matrix(y_test, y_pred_gpc)\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Gaussian Process Classifier\")\n",
    "# print(f\"Accuracy: {accuracy_gpc:.4f}\")\n",
    "# print(f\"Classification Report:\\n{report_gpc}\")\n",
    "# print(f\"Confusion Matrix:\\n{conf_matrix_gpc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57021961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "# from sklearn.gaussian_process.kernels import RBF, Matern\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Assuming 'medal' is the target variable\n",
    "# X = df.drop('medal', axis=1)\n",
    "# y = df['medal']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "#                                                     test_size=0.20, \n",
    "#                                                     random_state=42)\n",
    "\n",
    "# # Adjusting the kernel and its parameters\n",
    "# kernel = 1.0 * Matern(length_scale=1.0, nu=1.5)  # Example with Matern kernel\n",
    "# gpc = GaussianProcessClassifier(kernel=kernel,n_restarts_optimizer=9,\n",
    "#                                 optimizer='fmin_l_bfgs_b',\n",
    "#                                 random_state=42)\n",
    "\n",
    "# # Fit the model to the training data\n",
    "# gpc.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred_gpc = gpc.predict(X_test)\n",
    "\n",
    "# # Evaluate the model's performance\n",
    "# accuracy_gpc = accuracy_score(y_test, y_pred_gpc)\n",
    "# report_gpc = classification_report(y_test, y_pred_gpc)\n",
    "# conf_matrix_gpc = confusion_matrix(y_test, y_pred_gpc)\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Gaussian Process Classifier\")\n",
    "# print(f\"Accuracy: {accuracy_gpc:.4f}\")\n",
    "# print(f\"Classification Report:\\n{report_gpc}\")\n",
    "# print(f\"Confusion Matrix:\\n{conf_matrix_gpc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f9f4208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier, StackingClassifier, AdaBoostClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# # Assuming 'medal' is the target variable\n",
    "# X = df.drop('medal', axis=1)\n",
    "# y = df['medal']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize individual classifiers\n",
    "# rf = RandomForestClassifier()\n",
    "# knn = KNeighborsClassifier()\n",
    "# adaboost = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "# catboost_model = CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, loss_function='Logloss', random_state=42)\n",
    "\n",
    "# # Initialize StackingClassifier with a Decision Tree as the meta-classifier\n",
    "# stacking_clf = StackingClassifier(\n",
    "#     estimators=[('rf', rf), ('knn', knn), ('adaboost', adaboost), ('catboost', catboost_model)],\n",
    "#     final_estimator=DecisionTreeClassifier(),\n",
    "#     stack_method='auto',\n",
    "#     n_jobs=-1,  # Set the number of jobs to -1 for parallel processing\n",
    "#     passthrough=True\n",
    "# )\n",
    "\n",
    "# # Fit the StackingClassifier to the training data\n",
    "# stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred_stacking = stacking_clf.predict(X_test)\n",
    "\n",
    "# # Evaluate the model's performance\n",
    "# accuracy_stacking = accuracy_score(y_test, y_pred_stacking)\n",
    "# report_stacking = classification_report(y_test, y_pred_stacking)\n",
    "# conf_matrix_stacking = confusion_matrix(y_test, y_pred_stacking)\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Stacking Classifier\")\n",
    "# print(f\"Accuracy: {accuracy_stacking:.4f}\")\n",
    "# print(f\"Classification Report:\\n{report_stacking}\")\n",
    "# print(f\"Confusion Matrix:\\n{conf_matrix_stacking}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5e8817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp = pd.read_csv('../../Data/cleandata22-23/encoded_w_olympics_fx.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "048feb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp=olymp.drop(columns=['round_aafinal', 'round_teamfinal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2969e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp['round_0']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "603cee74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rank', 'D Score', 'E Score', 'Pen.', 'Total', 'year', 'Name', 'nation',\n",
       "       'round_final', 'round_qual', 'round_teamqual', 'round_0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olymp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8889fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired column order\n",
    "desired_order = ['Rank', 'D Score', 'E Score', 'Pen.', 'Total', 'year', 'Name', 'nation',\n",
    "       'round_0', 'round_final', 'round_qual']\n",
    "\n",
    "# Reorder the columns based on the desired order\n",
    "olymp = olymp[desired_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d909fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = clf.predict(olymp)\n",
    "y_pred = clf.predict(olymp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27129fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds  = pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a60967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "olymp['ypred']=ypreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ea22559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ypred\n",
       "0    2114\n",
       "1       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olymp['ypred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8220fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = olymp[olymp['ypred'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1aea79da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([642])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ed00a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Name_encoded values to filter by\n",
    "name_encoded_values = [642]\n",
    "\n",
    "# Create an empty set to store unique names\n",
    "unique_names = set()\n",
    "\n",
    "# Iterate through the DataFrame and add unique names to the set\n",
    "for index, row in fxnames.iterrows():\n",
    "    if row['Name_encoded'] in name_encoded_values:\n",
    "        unique_names.add(row['Name'])\n",
    "\n",
    "# Convert the set of unique names back to a list\n",
    "unique_names_list = list(unique_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18382f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simone biles']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd62ffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fxolymp['Name'] = fxolymp['Name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "292b9286",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_find = ['simone biles']\n",
    "\n",
    "# Filter the DataFrame to get the desired names and their corresponding countries\n",
    "result_df = fxolymp[fxolymp['Name'].isin(names_to_find)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc15f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=result_df[result_df['Apparatus']== 'FX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7858418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = result_df[result_df['Country']=='USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8165f643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['simone biles'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa['Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895437e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383e4636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
